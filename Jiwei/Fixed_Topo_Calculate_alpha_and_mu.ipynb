{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a14c096-9c92-46c6-ba84-cc8df2af5cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import math\n",
    "from pathlib import Path\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import gaussian_kde\n",
    "from autocatalytic_cores_lib import *\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from sympy import symbols, Matrix, diff, lambdify\n",
    "from scipy.linalg import eigvals\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.optimize import newton_krylov\n",
    "from scipy.sparse.linalg import gmres, LinearOperator\n",
    "from numpy.linalg import svd\n",
    "from scipy.optimize import linprog\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import bmat\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from scipy.linalg import eigh\n",
    "from scipy.optimize import fsolve\n",
    "from textwrap import dedent\n",
    "import networkx as nx   \n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbf0014-4412-4f52-8b43-325f662a0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neumann(object):\n",
    "\n",
    "    \"\"\"\n",
    "    This class describes the Generalized von Neumann growth model as it was\n",
    "    discussed in Kemeny et al. (1956, ECTA) and Gale (1960, Chapter 9.5):\n",
    "\n",
    "    Let:\n",
    "    n ... number of goods\n",
    "    m ... number of activities\n",
    "    A ... input matrix is m-by-n\n",
    "        a_{i,j} - amount of good j consumed by activity i\n",
    "    B ... output matrix is m-by-n\n",
    "        b_{i,j} - amount of good j produced by activity i\n",
    "\n",
    "    x ... intensity vector (m-vector) with non-negative entries\n",
    "        x'B - the vector of goods produced\n",
    "        x'A - the vector of goods consumed\n",
    "    p ... price vector (n-vector) with non-negative entries\n",
    "        Bp - the revenue vector for every activity\n",
    "        Ap - the cost of each activity\n",
    "\n",
    "    Both A and B have non-negative entries. Moreover, we assume that\n",
    "    (1) Assumption I (every good which is consumed is also produced):\n",
    "        for all j, b_{.,j} > 0, i.e. at least one entry is strictly positive\n",
    "    (2) Assumption II (no free lunch):\n",
    "        for all i, a_{i,.} > 0, i.e. at least one entry is strictly positive\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : array_like or scalar(float)\n",
    "        Part of the state transition equation.  It should be `n x n`\n",
    "    B : array_like or scalar(float)\n",
    "        Part of the state transition equation.  It should be `n x k`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A, B):\n",
    "\n",
    "        self.A, self.B = list(map(self.convert, (A, B)))\n",
    "        self.m, self.n = self.A.shape\n",
    "\n",
    "        # Check if (A, B) satisfy the basic assumptions\n",
    "        assert self.A.shape == self.B.shape, 'The input and output matrices \\\n",
    "              must have the same dimensions!'\n",
    "        assert (self.A >= 0).all() and (self.B >= 0).all(), 'The input and \\\n",
    "              output matrices must have only non-negative entries!'\n",
    "\n",
    "        # (1) Check whether Assumption I is satisfied:\n",
    "        if (np.sum(B, 0) <= 0).any():\n",
    "            self.AI = False\n",
    "        else:\n",
    "            self.AI = True\n",
    "\n",
    "        # (2) Check whether Assumption II is satisfied:\n",
    "        if (np.sum(A, 1) <= 0).any():\n",
    "            self.AII = False\n",
    "        else:\n",
    "            self.AII = True\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self):\n",
    "\n",
    "        me = \"\"\"\n",
    "        Generalized von Neumann expanding model:\n",
    "          - number of goods          : {n}\n",
    "          - number of activities     : {m}\n",
    "\n",
    "        Assumptions:\n",
    "          - AI:  every column of B has a positive entry    : {AI}\n",
    "          - AII: every row of A has a positive entry       : {AII}\n",
    "\n",
    "        \"\"\"\n",
    "        # Irreducible                                       : {irr}\n",
    "        return dedent(me.format(n=self.n, m=self.m,\n",
    "                                AI=self.AI, AII=self.AII))\n",
    "\n",
    "    def convert(self, x):\n",
    "        \"\"\"\n",
    "        Convert array_like objects (lists of lists, floats, etc.) into\n",
    "        well-formed 2D NumPy arrays\n",
    "        \"\"\"\n",
    "        return np.atleast_2d(np.asarray(x))\n",
    "\n",
    "\n",
    "    def bounds(self):\n",
    "        \"\"\"\n",
    "        Calculate the trivial upper and lower bounds for alpha (expansion rate)\n",
    "        and beta (interest factor). See the proof of Theorem 9.8 in Gale (1960)\n",
    "        \"\"\"\n",
    "\n",
    "        n, m = self.n, self.m\n",
    "        A, B = self.A, self.B\n",
    "\n",
    "        f = lambda α: ((B - α * A) @ np.ones((n, 1))).max()\n",
    "        g = lambda β: (np.ones((1, m)) @ (B - β * A)).min()\n",
    "\n",
    "        UB = fsolve(f, 1).item()  # Upper bound for α, β\n",
    "        LB = fsolve(g, 2).item()  # Lower bound for α, β\n",
    "\n",
    "        return LB, UB\n",
    "\n",
    "\n",
    "    def zerosum(self, γ, dual=False):\n",
    "        \"\"\"\n",
    "        Given gamma, calculate the value and optimal strategies of a\n",
    "        two-player zero-sum game given by the matrix\n",
    "\n",
    "                M(gamma) = B - gamma * A\n",
    "\n",
    "        Row player maximizing, column player minimizing\n",
    "\n",
    "        Zero-sum game as an LP (primal --> α)\n",
    "\n",
    "            max (0', 1) @ (x', v)\n",
    "            subject to\n",
    "            [-M', ones(n, 1)] @ (x', v)' <= 0\n",
    "            (x', v) @ (ones(m, 1), 0) = 1\n",
    "            (x', v) >= (0', -inf)\n",
    "\n",
    "        Zero-sum game as an LP (dual --> beta)\n",
    "\n",
    "            min (0', 1) @ (p', u)\n",
    "            subject to\n",
    "            [M, -ones(m, 1)] @ (p', u)' <= 0\n",
    "            (p', u) @ (ones(n, 1), 0) = 1\n",
    "            (p', u) >= (0', -inf)\n",
    "\n",
    "        Outputs:\n",
    "        --------\n",
    "        value: scalar\n",
    "            value of the zero-sum game\n",
    "\n",
    "        strategy: vector\n",
    "            if dual = False, it is the intensity vector,\n",
    "            if dual = True, it is the price vector\n",
    "        \"\"\"\n",
    "\n",
    "        A, B, n, m = self.A, self.B, self.n, self.m\n",
    "        M = B - γ * A\n",
    "\n",
    "        if dual == False:\n",
    "            # Solve the primal LP (for details see the description)\n",
    "            # (1) Define the problem for v as a maximization (linprog minimizes)\n",
    "            c = np.hstack([np.zeros(m), -1])\n",
    "\n",
    "            # (2) Add constraints :\n",
    "            # ... non-negativity constraints\n",
    "            bounds = tuple(m * [(0, None)] + [(None, None)])\n",
    "            # ... inequality constraints\n",
    "            A_iq = np.hstack([-M.T, np.ones((n, 1))])\n",
    "            b_iq = np.zeros((n, 1))\n",
    "            # ... normalization\n",
    "            A_eq = np.hstack([np.ones(m), 0]).reshape(1, m + 1)\n",
    "            b_eq = 1\n",
    "\n",
    "            res = linprog(c, A_ub=A_iq, b_ub=b_iq, A_eq=A_eq, b_eq=b_eq,\n",
    "                          bounds=bounds)\n",
    "\n",
    "        else:\n",
    "            # Solve the dual LP (for details see the description)\n",
    "            # (1) Define the problem for v as a maximization (linprog minimizes)\n",
    "            c = np.hstack([np.zeros(n), 1])\n",
    "\n",
    "            # (2) Add constraints :\n",
    "            # ... non-negativity constraints\n",
    "            bounds = tuple(n * [(0, None)] + [(None, None)])\n",
    "            # ... inequality constraints\n",
    "            A_iq = np.hstack([M, -np.ones((m, 1))])\n",
    "            b_iq = np.zeros((m, 1))\n",
    "            # ... normalization\n",
    "            A_eq = np.hstack([np.ones(n), 0]).reshape(1, n + 1)\n",
    "            b_eq = 1\n",
    "\n",
    "            res = linprog(c, A_ub=A_iq, b_ub=b_iq, A_eq=A_eq, b_eq=b_eq,\n",
    "                          bounds=bounds)\n",
    "\n",
    "        if res.status != 0 or res.x is None:\n",
    "            # LP infeasible or error\n",
    "            return np.nan, None\n",
    "\n",
    "        # Pull out the required quantities\n",
    "        value = res.x[-1]\n",
    "        strategy = res.x[:-1]\n",
    "\n",
    "        return value, strategy\n",
    "\n",
    "\n",
    "    def expansion(self, tol=1e-8, maxit=1000):\n",
    "        \"\"\"\n",
    "        The algorithm used here is described in Hamburger-Thompson-Weil\n",
    "        (1967, ECTA). It is based on a simple bisection argument and utilizes\n",
    "        the idea that for a given γ (= α or β), the matrix \"M = B - γ * A\"\n",
    "        defines a two-player zero-sum game, where the optimal strategies are\n",
    "        the (normalized) intensity and price vector.\n",
    "\n",
    "        Outputs:\n",
    "        --------\n",
    "        alpha: scalar\n",
    "            optimal expansion rate\n",
    "        \"\"\"\n",
    "\n",
    "        LB, UB = self.bounds()\n",
    "\n",
    "        for iter in range(maxit):\n",
    "\n",
    "            γ = (LB + UB) / 2\n",
    "            ZS = self.zerosum(γ=γ, dual=False)\n",
    "            V = ZS[0]     # value of the game with γ\n",
    "\n",
    "            if V >= 0:\n",
    "                LB = γ\n",
    "            else:\n",
    "                UB = γ\n",
    "\n",
    "            if abs(UB - LB) < tol:\n",
    "                γ = (UB + LB) / 2\n",
    "                x = self.zerosum(γ=γ)[1]\n",
    "                p = self.zerosum(γ=γ, dual=True)[1]\n",
    "                break\n",
    "\n",
    "        return γ, x, p\n",
    "\n",
    "    def interest(self, tol=1e-8, maxit=1000):\n",
    "        \"\"\"\n",
    "        The algorithm used here is described in Hamburger-Thompson-Weil\n",
    "        (1967, ECTA). It is based on a simple bisection argument and utilizes\n",
    "        the idea that for a given gamma (= alpha or beta),\n",
    "        the matrix \"M = B - γ * A\" defines a two-player zero-sum game,\n",
    "        where the optimal strategies are the (normalized) intensity and price\n",
    "        vector\n",
    "\n",
    "        Outputs:\n",
    "        --------\n",
    "        beta: scalar\n",
    "            optimal interest rate\n",
    "        \"\"\"\n",
    "\n",
    "        LB, UB = self.bounds()\n",
    "\n",
    "        for iter in range(maxit):\n",
    "            γ = (LB + UB) / 2\n",
    "            ZS = self.zerosum(γ=γ, dual=True)\n",
    "            V = ZS[0]\n",
    "\n",
    "            if V > 0:\n",
    "                LB = γ\n",
    "            else:\n",
    "                UB = γ\n",
    "\n",
    "            if abs(UB - LB) < tol:\n",
    "                γ = (UB + LB) / 2\n",
    "                p = self.zerosum(γ=γ, dual=True)[1]\n",
    "                x = self.zerosum(γ=γ)[1]\n",
    "                break\n",
    "\n",
    "        return γ, x, p\n",
    "\n",
    "def compute_von_neumann_alpha_beta(S_plus, S_minus, tol=1e-8):\n",
    "    \"\"\"\n",
    "    Compute von Neumann alpha (expansion), beta (interest),\n",
    "    and the optimal normalized flows for both problems.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    alpha : Optimal expansion rate.\n",
    "    beta : Optimal interest rate.\n",
    "    x_alpha : Optimal intensity vector (normalized flow) for expansion.\n",
    "    p_alpha : Optimal price vector for expansion.\n",
    "    x_beta : Optimal intensity vector (normalized flow) for interest.\n",
    "    p_beta : Optimal price vector for interest.\n",
    "    \"\"\"\n",
    "    \n",
    "    A = S_minus.T\n",
    "    B = S_plus.T\n",
    "    model = Neumann(A, B)\n",
    "\n",
    "    # alpha\n",
    "    alpha, x_alpha, p_alpha = model.expansion(tol=tol)\n",
    "\n",
    "    # beta\n",
    "    beta, x_beta, p_beta  = model.interest(tol=tol)\n",
    "\n",
    "    return alpha, beta, x_alpha, p_alpha, x_beta, p_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ffd79b8-4cc8-4d8a-adae-74b7179cfa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Praful MGF\n",
    "'''\n",
    "import algorithm_1 as algo1\n",
    "import auxiliary_functions as aux\n",
    "import algorithm_3 as algo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7486a730-2c40-4e9d-a21a-a7fcc04c4812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the topological growth bound\n",
    "def compute_topological_growth_bound(S_minus, alpha, x_alpha):\n",
    "    x_alpha = x_alpha / np.max(x_alpha)  # Normalize to make max(x_alpha) = 1\n",
    "    print(f\"{x_alpha}\")\n",
    "    sp = np.dot(S_minus, x_alpha)\n",
    "    mu = (alpha - 1) * sp.sum()\n",
    "    return mu\n",
    "\n",
    "def compute_Sx(S_plus, S_minus, x_alpha):\n",
    "    x_alpha = x_alpha / np.max(x_alpha)\n",
    "    Stot = S_plus - S_minus\n",
    "    sp = np.dot(Stot, x_alpha)\n",
    "    return sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f846e2-daa0-4149-9dd8-f8d09deb0257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_Random_Network(N_Y_raw, N_R_raw, ambiguity):\n",
    "\n",
    "    # Build Random Network\n",
    "    S_raw = np.zeros((N_Y_raw, N_R_raw))\n",
    "    S1_raw = np.zeros((N_Y_raw, N_R_raw))\n",
    "    \n",
    "    # Construct stoichiometric matrix\n",
    "    for i in range(N_R_raw):\n",
    "        species1 = random.randint(0, N_Y_raw - 1)\n",
    "        S_raw[species1][i] += 1\n",
    "        \n",
    "        species2 = random.randint(0, N_Y_raw - 1)\n",
    "        while not ambiguity and species2 == species1:\n",
    "            species2 = random.randint(0, N_Y_raw - 1)\n",
    "        S1_raw[species2][i] += 1\n",
    "            \n",
    "        # The order of a chemical reaction\n",
    "        total_order_for = random.randint(1, 2)\n",
    "        total_order_bac = random.randint(1, 2)\n",
    "        # Count the number of forward/backward reaction species already in the reaction\n",
    "        stoichio_for = 0\n",
    "        stoichio_bac = 0\n",
    "                \n",
    "        while stoichio_for < (total_order_for - 1):\n",
    "            species = random.randint(0, N_Y_raw - 1)\n",
    "            if ambiguity or S1_raw[species][i] == 0:\n",
    "                S_raw[species][i] += 1\n",
    "                stoichio_for += 1\n",
    "    \n",
    "        while stoichio_bac < (total_order_bac - 1):\n",
    "            species = random.randint(0, N_Y_raw - 1)\n",
    "            if ambiguity or S_raw[species][i] == 0:\n",
    "                S1_raw[species][i] += 1\n",
    "                stoichio_bac += 1\n",
    "    \n",
    "    Stot_raw = S1_raw - S_raw\n",
    "\n",
    "    '''\n",
    "    Reduce Matrix to Avoid Redundant and Confusion\n",
    "    '''\n",
    "    \n",
    "    # Remove all-zero rows (empty species)\n",
    "    # Species\n",
    "    row_keep = ~((S_raw==0).all(axis=1) & (S1_raw==0).all(axis=1))\n",
    "    S_raw  = S_raw[row_keep]\n",
    "    S1_raw = S1_raw[row_keep]\n",
    "\n",
    "    # Remove all-zero columns (reactions with net zero stoichiometry)\n",
    "    col_keep = ~((S_raw==0).all(axis=0) & (S1_raw==0).all(axis=0))\n",
    "    S_raw  = S_raw[:, col_keep]\n",
    "    S1_raw = S1_raw[:, col_keep]\n",
    "\n",
    "    # Remove duplicate columns\n",
    "    m = S_raw.shape[1]\n",
    "    keep = []\n",
    "    seen = set()\n",
    "    for j in range(m):\n",
    "        key = tuple(S_raw[:,j].tolist()) + tuple(S1_raw[:,j].tolist())\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            keep.append(j)\n",
    "    S_raw  = S_raw[:, keep]\n",
    "    S1_raw = S1_raw[:, keep]\n",
    "\n",
    "    # Record new parameters\n",
    "    S_plus = S1_raw\n",
    "    S_minus = S_raw\n",
    "    Stot = S_plus - S_minus\n",
    "    N_Y = Stot.shape[0]\n",
    "    N_R = Stot.shape[1]\n",
    "\n",
    "    df_Stot = pd.DataFrame(\n",
    "    Stot.astype(int),                        \n",
    "    index=range(1, Stot.shape[0]+1),         \n",
    "    columns=range(1, Stot.shape[1]+1)        \n",
    "    )\n",
    "    #print(\"Matrix Stot:\")\n",
    "    #print(df_Stot.to_string())\n",
    "    \n",
    "    # S_plus \n",
    "    df_Sp = pd.DataFrame(\n",
    "        S_plus.astype(int),\n",
    "        index=range(1, S_plus.shape[0]+1),\n",
    "        columns=range(1, S_plus.shape[1]+1)\n",
    "    )\n",
    "    #print(\"\\nS_plus:\")\n",
    "    #print(df_Sp.to_string())\n",
    "    \n",
    "    # S_minus \n",
    "    df_Sm = pd.DataFrame(\n",
    "        S_minus.astype(int),\n",
    "        index=range(1, S_minus.shape[0]+1),\n",
    "        columns=range(1, S_minus.shape[1]+1)\n",
    "    )\n",
    "    #print(\"\\nS_minus:\")\n",
    "    #print(df_Sm.to_string())\n",
    "    #print(\"NY =\", N_Y)\n",
    "    #print(\"NR =\", N_R)\n",
    "\n",
    "    return Stot, N_Y, N_R, S_plus, S_minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02508d9c-6afb-4166-b1c0-eb0882f77efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Construct_Kinetics(N_Y, N_R, S_plus, S_minus, degradation=False):\n",
    "    \"\"\"\n",
    "      - Initial concentration Y0\n",
    "      - Generalized Forward Rate constant kf\n",
    "      - Degradation kd\n",
    "    \"\"\"\n",
    "    Y0 = [random.uniform(1, 100.0) for _ in range(N_Y)]\n",
    "\n",
    "    kf = np.array([random.uniform(1e-12, 1.0) for _ in range(N_R)])\n",
    "\n",
    "    kf /= kf.max()\n",
    "    \n",
    "    # degradation degradation coefficient\n",
    "    kd = None\n",
    "    if degradation:\n",
    "        kd = 0.01 * np.array([random.uniform(0.95, 1.05) for _ in range(N_Y)])\n",
    "\n",
    "    return np.array(Y0), kf, kd\n",
    "\n",
    "def make_dydt_rescaled_func(N_Y, N_R, S_minus, S_plus, kf, kd, law = \"MA\"):\n",
    "    eps=1e-12\n",
    "    lambdas = []\n",
    "        \n",
    "    # net stoichiometry in the free (Y) part for each reaction l\n",
    "    netStoich_Y = np.zeros(N_R, dtype=int)\n",
    "    for l in range(N_R):\n",
    "        netStoich_Y[l] = int(np.sum(S_plus[0:, l]) - np.sum(S_minus[0:, l]))\n",
    "\n",
    "    def dydt_rescaled(t, Y_star_full):\n",
    "        Ys = Y_star_full[:N_Y]      # normalized Y^*(t)\n",
    "        Ys = np.clip(Ys, eps, 1.0) \n",
    "        Ys /= Ys.sum()\n",
    "        \n",
    "        logN = Y_star_full[-1]      # logN(t)\n",
    "\n",
    "        net_flux = np.zeros(N_R)\n",
    "\n",
    "        for l in range(N_R):\n",
    "            # --- forward flux density using Ystar ---\n",
    "            prodY = 1.0\n",
    "            for j in range(N_Y):\n",
    "                p = S_minus[j, l]\n",
    "                if p>0:\n",
    "                    prodY *= Ys[j]**p\n",
    "\n",
    "            if np.sum(S_minus[0:, l])==0:\n",
    "                v_f = 0.0\n",
    "            else:\n",
    "                if law==\"MM\":\n",
    "                    Kf = prodY\n",
    "                    v_f = 0.0 if (kf[l]+Kf)==0 else Kf/(kf[l]+Kf)\n",
    "                else:\n",
    "                    v_f = kf[l]*prodY\n",
    "\n",
    "            net_flux[l] = v_f\n",
    "            \n",
    "        lambda_t = float(np.dot(net_flux, netStoich_Y))\n",
    "        lambdas.append(lambda_t)\n",
    "\n",
    "        # dY*/dt\n",
    "        dYs = np.zeros(N_Y)\n",
    "        for j in range(N_Y):\n",
    "            row = S_plus[j,:] - S_minus[j,:]\n",
    "            dYs[j] = float(np.dot(row, net_flux)) - lambda_t*Ys[j]\n",
    "\n",
    "        # d(logN)/dt = lambda(t)\n",
    "        return np.concatenate([dYs, [lambda_t]])\n",
    "\n",
    "    return dydt_rescaled, lambdas\n",
    "    \n",
    "def Solve_Scaled_System(S_minus, S_plus, Y0, N_Y, N_R,\n",
    "                        kf, kd, dt, n_steps, threshold, extra_steps, law = \"MA\"):\n",
    "    \"\"\"\n",
    "    Fix step dt，simulate n_steps：\n",
    "      - t_eval      (length = n_steps+1)\n",
    "      - Ystar_traj  (shape (N_Y, n_steps+1))\n",
    "      - Yabs_traj   (shape (N_Y, n_steps+1))\n",
    "      - lambdas     (length = n_steps+1)\n",
    "      - N_traj      (length = n_steps+1)\n",
    "    \"\"\"\n",
    "    def single_run(Y0, n_steps):\n",
    "        # initialize N, normalize Y*\n",
    "        N0 = np.sum(Y0)\n",
    "        Ystar0 = Y0 / N0\n",
    "        logN0 = math.log(N0)\n",
    "        y0 = np.concatenate([Ystar0, [logN0]])\n",
    "    \n",
    "        ttot = dt * n_steps\n",
    "        t_eval = np.linspace(0, ttot, n_steps + 1)\n",
    "    \n",
    "        dydt_rescaled, lambdas = make_dydt_rescaled_func(\n",
    "            N_Y, N_R, S_minus, S_plus, kf, kd, law\n",
    "        )\n",
    "    \n",
    "        sol = solve_ivp(\n",
    "            fun=lambda t, y: dydt_rescaled(t, y),\n",
    "            t_span=[0, ttot],\n",
    "            y0=y0,\n",
    "            method=\"LSODA\",\n",
    "            dense_output=False,\n",
    "            t_eval=t_eval,\n",
    "            rtol=1e-6,\n",
    "            atol=1e-8\n",
    "        )\n",
    "    \n",
    "        Ystar_traj = sol.y[:N_Y, :]             # normalize Y^*(t)\n",
    "        logN_traj = sol.y[N_Y, :]               # logN(t)\n",
    "        N_traj = np.exp(logN_traj)              # exact N(t)\n",
    "        Yabs_traj = Ystar_traj * N_traj         # exact Y(t) = N(t)*Y^*(t)\n",
    "    \n",
    "        return t_eval, Ystar_traj, Yabs_traj, lambdas, N_traj, dydt_rescaled\n",
    "\n",
    "    t_eval, Ystar_traj, Yabs_traj, lambdas, N_traj, dydt_rescaled = single_run(Y0, n_steps)\n",
    "\n",
    "    \"\"\"\n",
    "    compute the residual of differencial equation and check if it reach the convergence requirement\n",
    "    and add additional steps if not\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "        # the last time point\n",
    "        q_final = Ystar_traj[:, -1]\n",
    "        lambda_final = lambdas[-1]\n",
    "        logN_final = math.log(N_traj[-1])\n",
    "        # compute residual dY*/dt\n",
    "        d_full = dydt_rescaled(0.0, np.concatenate([q_final, [logN_final]]))\n",
    "        residual = np.max(np.abs(d_full[:N_Y]))\n",
    "        if residual < threshold:\n",
    "            break\n",
    "\n",
    "        # if need to run extra_steps\n",
    "        Y0_new = Yabs_traj[:, -1]\n",
    "        t_ext, Ystar_ext, Yabs_ext, lambda_ext, N_ext, _ = single_run(Y0_new, extra_steps)\n",
    "\n",
    "        # conjugate data\n",
    "        t_ext_shifted = t_ext[1:] + t_eval[-1]\n",
    "        t_eval = np.concatenate([t_eval, t_ext_shifted])\n",
    "        Ystar_traj = np.hstack([Ystar_traj, Ystar_ext[:, 1:]])\n",
    "        Yabs_traj  = np.hstack([Yabs_traj,  Yabs_ext[:,  1:]])\n",
    "        lambdas    = lambdas + lambda_ext[1:]\n",
    "        N_traj     = np.concatenate([N_traj, N_ext[1:]])\n",
    "\n",
    "    return t_eval, Ystar_traj, Yabs_traj, lambdas, N_traj\n",
    "    \n",
    "# =============================================================================\n",
    "# long-term growth rate\n",
    "# =============================================================================\n",
    "def compute_long_term_growth_rate(lambdas):\n",
    "    \"\"\"\n",
    "    Average the last last_n values of the lambda(t) sequence to obtain an estimate of the exponential growth rate λ\n",
    "    \"\"\"\n",
    "    if len(lambdas) == 0:\n",
    "       return 0.0\n",
    "    return lambdas[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50501bb7-2bcf-40b3-a95e-f8cc546ed40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_steadystate_by_newton_krylov(\n",
    "    S_plus, S_minus, N_Y, N_R, Y0, kf,\n",
    "    law='MA',\n",
    "    dt=1e-3, n_steps=20000,\n",
    "    tol=1e-7, maxiter=5000, inner_maxiter=200): \n",
    "    '''\n",
    "    Perform time-dependent simulation until t = dt * n_steps, obtaining initial q0, lambda0.\n",
    "    Solve F(q,λ)=0 using Newton–Krylov, with parameterization ensuring q ∈ simplex.\n",
    "    '''\n",
    "    # =============================================================================\n",
    "    # —— Simulation for some steps to get initial condition for equation —— \n",
    "    # =============================================================================\n",
    "    lambdas = []\n",
    "    Y0 = np.asarray(Y0, float)\n",
    "    N0 = Y0.sum()\n",
    "    Ystar0 = Y0 / N0\n",
    "    logN0 = np.log(N0)\n",
    "    y0 = np.concatenate([Ystar0, [logN0]])\n",
    "\n",
    "    # netStoich\n",
    "    netStoich_Y = np.zeros(N_R, dtype=int)\n",
    "    for l in range(N_R):\n",
    "        netStoich_Y[l] = int(np.sum(S_plus[0:, l]) - np.sum(S_minus[0:, l]))\n",
    "\n",
    "    def dydt_rescaled(t, y):\n",
    "        Ys = y[:N_Y]\n",
    "        Ys = np.clip(Ys, 1e-12, None)\n",
    "        Ys /= Ys.sum()\n",
    "        \n",
    "        net_flux = np.zeros(N_R)\n",
    "\n",
    "        for l in range(N_R):\n",
    "            # --- forward flux density using Ystar ---\n",
    "            prodY = 1.0\n",
    "            for j in range(N_Y):\n",
    "                p = S_minus[j, l]\n",
    "                if p>0:\n",
    "                    prodY *= Ys[j]**p\n",
    "\n",
    "            if np.sum(S_minus[0:, l])==0:\n",
    "                v_f = 0.0\n",
    "            else:\n",
    "                if law==\"MM\":\n",
    "                    Kf = prodY\n",
    "                    v_f = 0.0 if (kf[l]+Kf)==0 else Kf/(kf[l]+Kf)\n",
    "                else:\n",
    "                    v_f = kf[l]*prodY\n",
    "\n",
    "            net_flux[l] = v_f\n",
    "            \n",
    "        lambda_t = float(np.dot(net_flux, netStoich_Y))\n",
    "        lambdas.append(lambda_t)\n",
    "\n",
    "        # dY*/dt\n",
    "        dYs = np.zeros(N_Y)\n",
    "        for j in range(N_Y):\n",
    "            row = S_plus[j,:] - S_minus[j,:]\n",
    "            dYs[j] = float(np.dot(row, net_flux)) - lambda_t*Ys[j]\n",
    "\n",
    "        # d(logN)/dt = lambda(t)\n",
    "        return np.concatenate([dYs, [lambda_t]])\n",
    "\n",
    "    ttot = dt * n_steps\n",
    "    t_eval = np.linspace(0, ttot, n_steps + 1)\n",
    "    sol = solve_ivp(\n",
    "        fun=dydt_rescaled,\n",
    "        t_span=[0, ttot],\n",
    "        y0=y0,\n",
    "        method=\"LSODA\",\n",
    "        t_eval=t_eval,\n",
    "        rtol=1e-6, atol=1e-8\n",
    "    )\n",
    "    Ystar_traj = sol.y[:N_Y, :]\n",
    "    Ys_final = Ystar_traj[:, -1]\n",
    "\n",
    "    # initial guess q0, lambda0\n",
    "    q0 = np.clip(Ys_final, 1e-12, None)\n",
    "    q0 /= q0.sum()\n",
    "    J0 = np.array([\n",
    "        kf[r] * np.prod(q0**S_minus[:, r])\n",
    "        for r in range(N_R)\n",
    "    ])\n",
    "    lam0 = float(netStoich_Y.dot(J0))\n",
    "\n",
    "    # =============================================================================\n",
    "    # —— Newton–Krylov solve steady state equation —— \n",
    "    #    Parameterization: u_vars ∈ ℝ^(N_Y-1)， λ ∈ ℝ\n",
    "    # =============================================================================\n",
    "\n",
    "    # construct residual: x = [u_vars (N_Y-1), λ]\n",
    "    def residual_mapped(x):\n",
    "        u_vars = x[:N_Y-1]\n",
    "        lam = x[N_Y-1]\n",
    "        # rebuild u_full, set u_N=0\n",
    "        u_full = np.concatenate([u_vars, [0.0]])\n",
    "        # use softmax projection to q\n",
    "        expu = np.exp(u_full - u_full.max())\n",
    "        q = expu / expu.sum()\n",
    "        # compute flow\n",
    "        J = np.array([\n",
    "            kf[r] * np.prod(q**S_minus[:, r])\n",
    "            for r in range(N_R)\n",
    "        ])\n",
    "        # F(q, λ) = S*J - λ*q\n",
    "        return (S_plus - S_minus).dot(J) - lam * q\n",
    "\n",
    "    # initial x0: use q0 project back to u0_vars\n",
    "    u0_full = np.log(q0)\n",
    "    # gauge: set u_N = 0, others minus u_N\n",
    "    u0_vars = u0_full[:-1] - u0_full[-1]\n",
    "    x0 = np.concatenate([u0_vars, [lam0]])\n",
    "    \n",
    "    try:\n",
    "        sol_nk = newton_krylov(\n",
    "            residual_mapped,\n",
    "            x0,\n",
    "            method='lgmres',\n",
    "            inner_maxiter=inner_maxiter,\n",
    "            f_tol=tol,\n",
    "            maxiter=maxiter,\n",
    "            line_search=True,\n",
    "        )\n",
    "        \n",
    "    except Exception as e_krylov:\n",
    "        sol_nk = broyden1(\n",
    "            residual_mapped,\n",
    "            x0,\n",
    "            f_tol=tol,\n",
    "            maxiter=maxiter\n",
    "        )\n",
    "        \n",
    "    except Exception as e_broyden:\n",
    "        sol_nk = anderson(\n",
    "            residual_mapped,\n",
    "            x0,\n",
    "            f_tol=tol,\n",
    "            maxiter=maxiter\n",
    "        )\n",
    "\n",
    "    # slove q*, λ*\n",
    "    u_star_vars = sol_nk[:N_Y-1]\n",
    "    lam_star   = sol_nk[N_Y-1]\n",
    "    u_star_full = np.concatenate([u_star_vars, [0.0]])\n",
    "    expu = np.exp(u_star_full - u_star_full.max())\n",
    "    q_star = expu / expu.sum()\n",
    "\n",
    "    # final J_star\n",
    "    J_star = np.array([\n",
    "        kf[r] * np.prod(q_star**S_minus[:, r])\n",
    "        for r in range(N_R)\n",
    "    ])\n",
    "\n",
    "    return q_star, lam_star, J_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1688b5f8-3ee0-4f07-a7bb-948ac7bf04ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Single network\n",
    "'''\n",
    "def main_example():\n",
    "    \n",
    "    # Realization 1817\n",
    "    \n",
    "    S_plus = np.array ([\n",
    "    [0,  1,  1,  0,  0,  0,  0,  0],\n",
    "    [0,  0,  0,  0,  2,  1,  1,  0],\n",
    "    [1,  0,  0,  1,  0,  0,  0,  1]\n",
    "    ])\n",
    "    \n",
    "    S_minus = np.array([\n",
    "    [0,  0,  0,  1,  1,  0,  1,  1],\n",
    "    [1,  0,  2,  1,  0,  0,  0,  0],\n",
    "    [0,  2,  0,  0,  1,  2,  1,  0]\n",
    "    ])\n",
    "    '''\n",
    "    \n",
    "    S_plus = np.array ([\n",
    "    [0,  1,  1,  0,    0,  0,  0],\n",
    "    [0,  0,  0,  0,    1,  1,  0],\n",
    "    [1,  0,  0,  1,    0,  0,  1]\n",
    "    ])\n",
    "    \n",
    "    S_minus = np.array([\n",
    "    [0,  0,  0,  1,    0,  1,  1],\n",
    "    [1,  0,  2,  1,    0,  0,  0],\n",
    "    [0,  2,  0,  0,    2,  1,  0]\n",
    "    ])\n",
    "    \n",
    "\n",
    "    S_plus = np.array ([\n",
    "    [0,  1,  1,  0,  0,  0,    0],\n",
    "    [0,  0,  0,  0,  2,  1,    0],\n",
    "    [1,  0,  0,  1,  0,  0,    1]\n",
    "    ])\n",
    "    \n",
    "    S_minus = np.array([\n",
    "    [0,  0,  0,  1,  1,  0,    1],\n",
    "    [1,  0,  2,  1,  0,  0,    0],\n",
    "    [0,  2,  0,  0,  1,  2,    0]\n",
    "    ])\n",
    "    '''\n",
    "    \n",
    "    _, _, auto = aux.checkAutonomy(S_minus, S_plus)\n",
    "    if auto:\n",
    "        print(\"Found an autonomous network.\")\n",
    "\n",
    "    N_Y = 3\n",
    "    N_R = 8\n",
    "    print(f\"NY = {N_Y}\")\n",
    "    print(f\"NR = {N_R}\")\n",
    "\n",
    "    '''\n",
    "    initial conditions\n",
    "    '''\n",
    "    Y0 = [1,40,3] # Y0 should have no influence about steady state solution\n",
    "    kf = [1.0, \n",
    "          1.0,\n",
    "          1.0,\n",
    "          1.0,\n",
    "          1.0,\n",
    "          1.0,\n",
    "          1.0,\n",
    "          1.0]\n",
    "    kd = None\n",
    "\n",
    "    flux, mgf, *_ = algo1.growthRateGraph(S_plus, S_minus, max_steps = 1000, time_limit_iteration = 100)\n",
    "    print(f\"mgf = {mgf:.5f}\")\n",
    "    print(\"\\nflux = \",flux)\n",
    "    \n",
    "    alpha, beta, x_alpha, p_alpha, x_beta, p_beta = compute_von_neumann_alpha_beta(S_plus, S_minus)\n",
    "    sp_growth = compute_Sx(S_plus, S_minus, x_alpha)\n",
    "    mu = compute_topological_growth_bound(S_minus, alpha, x_alpha)\n",
    "    sp_distri = sp_growth/mu\n",
    "    print(f\"α = {alpha:.5f},  β = {beta:.5f}, μ = {mu:.5f}\")\n",
    "    print(f\"optimal flow = {x_alpha}, S*x = {sp_growth}, species distribution = {sp_distri}\")\n",
    "    \n",
    "    dt = 1e-4\n",
    "    n_steps = 2500000\n",
    "    t_eval, Ystar_traj, Yabs, mus, N_traj = Solve_Scaled_System(\n",
    "        S_minus, S_plus, Y0, N_Y, N_R,\n",
    "        kf, kd, dt, n_steps, threshold = 1e-4,\n",
    "        extra_steps = 100000, law = \"MA\"\n",
    "    )\n",
    "\n",
    "    # compute long-term growth rate λ\n",
    "    lam = compute_long_term_growth_rate(mus)\n",
    "\n",
    "    print(\"Result of time evolution:\")\n",
    "    print(f\"Steady‐state composition = {Ystar_traj[:, -1]}\")\n",
    "    print(f\"Long-term growth rate = {lam}\")\n",
    "\n",
    "    q, lam, J = solve_steadystate_by_newton_krylov(S_plus, S_minus, N_Y, N_R, Y0, kf)\n",
    "\n",
    "    print(\"Solve NESS equation\")\n",
    "    print(\"Steady‐state composition q*:\", q)\n",
    "    print(\"\\n growth rate λ:\", lam)\n",
    "    print(\"\\nStaedy state flow:\", J)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e675430-79ea-4937-af06-23e24415916e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found an autonomous network.\n",
      "NY = 3\n",
      "NR = 8\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "mgf = 0.85809\n",
      "\n",
      "flux =  [1000.          368.16467204    0.            0.          429.04649408\n",
      "    0.            0.            0.        ]\n",
      "[1.         0.36816294 0.         0.         0.42904716 0.\n",
      " 0.         0.        ]\n",
      "α = 0.85809,  β = 0.85809, μ = -0.36816\n",
      "optimal flow = [0.55641797 0.20485248 0.         0.         0.23872955 0.\n",
      " 0.         0.        ], S*x = [-0.06088423 -0.14190567 -0.16537304], species distribution = [0.16537305 0.38544258 0.44918439]\n",
      "Result of time evolution:\n",
      "Steady‐state composition = [0.20456025 0.36149947 0.43394028]\n",
      "Long-term growth rate = -0.670005556256553\n",
      "Solve NESS equation\n",
      "Steady‐state composition q*: [0.20456025 0.36149947 0.43394028]\n",
      "\n",
      " growth rate λ: -0.6700055562565531\n",
      "\n",
      "Staedy state flow: [0.36149947 0.18830417 0.13068186 0.07394842 0.08876693 0.18830417\n",
      " 0.08876693 0.20456025]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b9e1a5-c6f2-4445-90f9-cafb6e59fca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
