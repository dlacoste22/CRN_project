{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2da049-9af2-4e86-b501-134e3b9130a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import math\n",
    "from pathlib import Path\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from types import SimpleNamespace\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from autocatalytic_cores_lib import *\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from sympy import symbols, Matrix, diff, lambdify\n",
    "from scipy.linalg import eigvals\n",
    "from numpy.linalg import svd\n",
    "from scipy.optimize import linprog\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import bmat\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from scipy.linalg import eigh\n",
    "from scipy.optimize import fsolve\n",
    "from textwrap import dedent\n",
    "import networkx as nx   \n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1510657-d5b7-451e-b5d7-60fb0dd0f517",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3969b71-6c5a-46cb-9725-a79732d1f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- N_X_raw: Number of species in the original system\n",
    "- N_Y_raw: Number of invading species\n",
    "- N_R: Number of reactions\n",
    "- ttot: Total simulation time\n",
    "- dt: Time step for integration\n",
    "- Runs: Number of simulation runs\n",
    "- diluted: Whether invaders interact with the original species\n",
    "- ambiguity: Allows for flexible reaction assignments\n",
    "- law: Defines reaction kinetics (e.g., Michaelis-Menten)\n",
    "- autonomy: If invaders can react among themselves\n",
    "- degradation: Whether degradation terms are included\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30916ab9-9abe-4631-ab4d-706e0e58316b",
   "metadata": {},
   "source": [
    "# Generate Random Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54e8d9a-fcb4-4b79-9405-2dfb2b778438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_Random_Network(N_X_raw, N_Y_raw, N_R_raw, diluted, ambiguity, autonomy):\n",
    "\n",
    "    # Check Condition Consistency\n",
    "    if diluted and not autonomy:\n",
    "        raise ValueError(\"Impossible to ask for TOP conditions AND allowing non-autonomy\")\n",
    "\n",
    "    # Build Random Network\n",
    "    S_raw = np.zeros((N_X_raw + N_Y_raw, N_R_raw))\n",
    "    S1_raw = np.zeros((N_X_raw + N_Y_raw, N_R_raw))\n",
    "    \n",
    "    # Construct stoichiometric matrix\n",
    "    for i in range(N_R_raw):\n",
    "        species1 = random.randint(0, N_Y_raw - 1)\n",
    "        S_raw[N_X_raw + species1][i] += 1\n",
    "        \n",
    "        if autonomy:\n",
    "            species2 = random.randint(0, N_Y_raw - 1)\n",
    "            while not ambiguity and species2 == species1:\n",
    "                species2 = random.randint(0, N_Y_raw - 1)\n",
    "            S1_raw[N_X_raw + species2][i] += 1\n",
    "            \n",
    "        # The order of a chemical reaction\n",
    "        total_order_for = random.randint(1, 3)\n",
    "        total_order_bac = random.randint(1, 3)\n",
    "        # Count the number of forward/backward reaction species already in the reaction\n",
    "        stoichio_for = 0\n",
    "        stoichio_bac = 0\n",
    "    \n",
    "        while stoichio_for < total_order_for - 1:\n",
    "            # when not diluted, we count in N_Y_raw\n",
    "            species = random.randint(0, N_X_raw + (N_Y_raw if not diluted else 0) - 1)\n",
    "            if ambiguity or S1_raw[species][i] == 0:\n",
    "                S_raw[species][i] += 1\n",
    "                stoichio_for += 1\n",
    "    \n",
    "        while stoichio_bac < (total_order_bac - (1 if autonomy else 0)):\n",
    "            species = random.randint(0, N_X_raw + N_Y_raw - 1)\n",
    "            if ambiguity or S_raw[species][i] == 0:\n",
    "                S1_raw[species][i] += 1\n",
    "                stoichio_bac += 1\n",
    "    \n",
    "    Stot_raw = S1_raw - S_raw\n",
    "\n",
    "    '''\n",
    "    Reduce Matrix to Avoid Redundant and Confusion\n",
    "    '''\n",
    "    \n",
    "    # Remove all-zero rows (empty species)\n",
    "    # Species\n",
    "    row_keep = ~((S_raw==0).all(axis=1) & (S1_raw==0).all(axis=1))\n",
    "    S_raw  = S_raw[row_keep]\n",
    "    S1_raw = S1_raw[row_keep]\n",
    "\n",
    "    # Remove all-zero columns (reactions with net zero stoichiometry)\n",
    "    col_keep = ~((S_raw==0).all(axis=0) & (S1_raw==0).all(axis=0))\n",
    "    S_raw  = S_raw[:, col_keep]\n",
    "    S1_raw = S1_raw[:, col_keep]\n",
    "\n",
    "    # Remove duplicate columns\n",
    "    m = S_raw.shape[1]\n",
    "    keep = []\n",
    "    seen = set()\n",
    "    for j in range(m):\n",
    "        key = tuple(S_raw[:,j].tolist()) + tuple(S1_raw[:,j].tolist())\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            keep.append(j)\n",
    "    S_raw  = S_raw[:, keep]\n",
    "    S1_raw = S1_raw[:, keep]\n",
    "\n",
    "    # Record new parameters\n",
    "    S_plus = S1_raw\n",
    "    S_minus = S_raw\n",
    "    Stot = S_plus - S_minus\n",
    "    kept_species_idx = np.where(row_keep)[0]\n",
    "    N_X = sum(i< N_X_raw for i in kept_species_idx)\n",
    "    N_Y = sum(N_X_raw <= i < N_X_raw+N_Y_raw for i in kept_species_idx)\n",
    "    N_R = Stot.shape[1]\n",
    "\n",
    "    df_Stot = pd.DataFrame(\n",
    "    Stot.astype(int),                        \n",
    "    index=range(1, Stot.shape[0]+1),         \n",
    "    columns=range(1, Stot.shape[1]+1)        \n",
    "    )\n",
    "    print(\"Matrix Stot:\")\n",
    "    print(df_Stot.to_string())\n",
    "    \n",
    "    # S_plus \n",
    "    df_Sp = pd.DataFrame(\n",
    "        S_plus.astype(int),\n",
    "        index=range(1, S_plus.shape[0]+1),\n",
    "        columns=range(1, S_plus.shape[1]+1)\n",
    "    )\n",
    "    print(\"\\nS_plus:\")\n",
    "    print(df_Sp.to_string())\n",
    "    \n",
    "    # S_minus \n",
    "    df_Sm = pd.DataFrame(\n",
    "        S_minus.astype(int),\n",
    "        index=range(1, S_minus.shape[0]+1),\n",
    "        columns=range(1, S_minus.shape[1]+1)\n",
    "    )\n",
    "    print(\"\\nS_minus:\")\n",
    "    print(df_Sm.to_string())\n",
    "    print(\"NX =\", N_X)\n",
    "    print(\"NY =\", N_Y)\n",
    "    print(\"NR =\", N_R)\n",
    "\n",
    "    return Stot, N_X, N_Y, N_R, S_plus, S_minus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a4e069-0d80-4a9e-a6d0-1295a26f7108",
   "metadata": {},
   "source": [
    "# Compute Null Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165b0ef-8212-41b4-881f-d98ceeb355d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_null_space(S_minus, S_plus, tol=1e-12):\n",
    "    S = S_plus - S_minus\n",
    "    m, n = S.shape\n",
    "    U, sigma, Vt = svd(S, full_matrices=True)\n",
    "    rank = np.sum(sigma > tol)\n",
    "    # Left nullspace: y^T S = 0\n",
    "    dimL = m - rank\n",
    "    basisL = U[:, rank:] if dimL > 0 else np.zeros((m, 0))\n",
    "    # Right nullspace: S x = 0\n",
    "    dimR = n - rank\n",
    "    basisR = Vt[rank:, :].T if dimR > 0 else np.zeros((n, 0))\n",
    "    return basisL, dimL, basisR, dimR\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ae049-9575-4bbc-bcf0-20c567b982c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaa86040-79de-4980-8fec-89a507d40f80",
   "metadata": {},
   "source": [
    "# Praful's MGF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208d1b77-33bc-4bd6-b93f-67b41d5def90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import algorithm_1 as algo1\n",
    "import auxiliary_functions as aux\n",
    "import algorithm_3 as algo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79006176-9b37-4c92-846e-59be96e90238",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MGF calculation:\n",
    "flux, alpha, _, _ = algo1.growthRateGraph(output_matrix, input_matrix, max_steps, time_limit_iteration)\n",
    "\n",
    "Check autonomy:\n",
    "_, _, auto = aux.checkAutonomy(input_matrix, output_matrix)\n",
    "\n",
    "Find strongest subnetworks:\n",
    "algo3.growthRateInSubgraphDefinitive(input_matrix, output_matrix, nameScenario, time_limit_iteration, ecoli_species)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd93d8c-e84d-418f-8c54-f02e877a0b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae586e1-ac32-496b-81f6-837096876720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c6a2fd7-5246-46ef-8eef-56e083cf3c5f",
   "metadata": {},
   "source": [
    "# MGF Calculation and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5e360cd-fdc0-482b-b270-e8f328678b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We can directly call Praful's code for computing MGF\n",
    "And also the one from Von Neumann model tutorial \n",
    "only for networks fit autonomous conditions\n",
    "instead of using our self-bulid one\n",
    "'''\n",
    "\n",
    "def extract_candidate_cores(df, N_X, N_Y, N_R):\n",
    "    \"\"\"\n",
    "    From DataFrame with columns AC, M1..Mn, R1..Rm,\n",
    "    returns list of {'AC', 'species', 'reactions'}.\n",
    "    \"\"\"\n",
    "    cores = []\n",
    "    for _, row in df.iterrows():\n",
    "        sp = [i for i in range(N_X + N_Y) if row.get(f\"M{i+1}\", 0) >= 0.5]\n",
    "        rx = [j for j in range(N_R) if row.get(f\"R{j+1}\", 0) >= 0.5]\n",
    "        if sp and rx:\n",
    "            cores.append({'AC': row.get(\"AC\"), 'species': sp, 'reactions': rx})\n",
    "    return cores\n",
    "\n",
    "def identify_and_score_cores(S_minus, S_plus, Stot, N_X, N_Y, N_R, output_dir):\n",
    "    \"\"\"\n",
    "    1) Find forward cores on Stot.\n",
    "    2) Find reverse cores on -Stot.\n",
    "    3) For each core, compute its true MGF in the original direction.\n",
    "    Returns a list of dicts with keys:\n",
    "      core, species, reactions, alpha, optimal_flow\n",
    "    \"\"\"\n",
    "\n",
    "    # forward cores\n",
    "    fwd_file = os.path.join(output_dir, \"cores_forward.xlsx\")\n",
    "    _ = ComputeAutocatalyticCores(Stot, fwd_file)\n",
    "    df_fwd = pd.read_excel(fwd_file)\n",
    "    forwards = extract_candidate_cores(df_fwd, N_X, N_Y, N_R)\n",
    "\n",
    "    # reverse cores\n",
    "    rev_file = os.path.join(output_dir, \"cores_reverse.xlsx\")\n",
    "    _ = ComputeAutocatalyticCores(-Stot, rev_file)\n",
    "    df_rev = pd.read_excel(rev_file)\n",
    "    reverses = extract_candidate_cores(df_rev, N_X, N_Y, N_R)\n",
    "\n",
    "    results = []\n",
    "    # score forward\n",
    "    for core in forwards:\n",
    "        SM_sub = Stot[np.ix_(core['species'], core['reactions'])]\n",
    "        S_plus_sub = np.where(SM_sub > 0, SM_sub, 0)\n",
    "        S_minus_sub = np.where(SM_sub < 0, -SM_sub, 0)\n",
    "        alpha, flow = dinkelbach_mgf(S_plus_sub, S_minus_sub)\n",
    "        label = f\"Forward AC {int(core['AC'])}\"\n",
    "        results.append({\n",
    "            'core': label,\n",
    "            'species': core['species'],\n",
    "            'reactions': core['reactions'],\n",
    "            'alpha': alpha,\n",
    "            'optimal_flow': flow\n",
    "        })\n",
    "\n",
    "    # score reverse\n",
    "    for core in reverses:\n",
    "        SM_sub = Stot[np.ix_(core['species'], core['reactions'])]\n",
    "        S_plus_sub = np.where(SM_sub > 0, SM_sub, 0)\n",
    "        S_minus_sub = np.where(SM_sub < 0, -SM_sub, 0)\n",
    "        alpha_inv, flow = dinkelbach_mgf(S_plus_sub, S_minus_sub)\n",
    "        # alpha = 1.0/alpha_inv if alpha_inv != 0 else 0.0\n",
    "        # print(f\"Reverse core {core['AC']} actual alpha (1/alpha_inv): {alpha:.5f}\")\n",
    "        label = f\"Reverse AC {int(core['AC'])}\"\n",
    "        results.append({\n",
    "            'core': label,\n",
    "            'species': core['species'],\n",
    "            'reactions': core['reactions'],\n",
    "            'alpha': alpha_inv,\n",
    "            'optimal_flow': flow\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad3caf-69f6-41db-a628-7009a2509fc4",
   "metadata": {},
   "source": [
    "# Von Neumann Growth Factor \n",
    "\n",
    "From tutorial Von Neumann Growth Model (and a Generalization) \n",
    "\n",
    "https://python.quantecon.org/von_neumann_model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5d1a54-541d-43bf-a8b0-11245d20edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neumann(object):\n",
    "\n",
    "    \"\"\"\n",
    "    This class describes the Generalized von Neumann growth model as it was\n",
    "    discussed in Kemeny et al. (1956, ECTA) and Gale (1960, Chapter 9.5):\n",
    "\n",
    "    Let:\n",
    "    n ... number of goods\n",
    "    m ... number of activities\n",
    "    A ... input matrix is m-by-n\n",
    "        a_{i,j} - amount of good j consumed by activity i\n",
    "    B ... output matrix is m-by-n\n",
    "        b_{i,j} - amount of good j produced by activity i\n",
    "\n",
    "    x ... intensity vector (m-vector) with non-negative entries\n",
    "        x'B - the vector of goods produced\n",
    "        x'A - the vector of goods consumed\n",
    "    p ... price vector (n-vector) with non-negative entries\n",
    "        Bp - the revenue vector for every activity\n",
    "        Ap - the cost of each activity\n",
    "\n",
    "    Both A and B have non-negative entries. Moreover, we assume that\n",
    "    (1) Assumption I (every good which is consumed is also produced):\n",
    "        for all j, b_{.,j} > 0, i.e. at least one entry is strictly positive\n",
    "    (2) Assumption II (no free lunch):\n",
    "        for all i, a_{i,.} > 0, i.e. at least one entry is strictly positive\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : array_like or scalar(float)\n",
    "        Part of the state transition equation.  It should be `n x n`\n",
    "    B : array_like or scalar(float)\n",
    "        Part of the state transition equation.  It should be `n x k`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A, B):\n",
    "\n",
    "        self.A, self.B = list(map(self.convert, (A, B)))\n",
    "        self.m, self.n = self.A.shape\n",
    "\n",
    "        # Check if (A, B) satisfy the basic assumptions\n",
    "        assert self.A.shape == self.B.shape, 'The input and output matrices \\\n",
    "              must have the same dimensions!'\n",
    "        assert (self.A >= 0).all() and (self.B >= 0).all(), 'The input and \\\n",
    "              output matrices must have only non-negative entries!'\n",
    "\n",
    "        # (1) Check whether Assumption I is satisfied:\n",
    "        if (np.sum(B, 0) <= 0).any():\n",
    "            self.AI = False\n",
    "        else:\n",
    "            self.AI = True\n",
    "\n",
    "        # (2) Check whether Assumption II is satisfied:\n",
    "        if (np.sum(A, 1) <= 0).any():\n",
    "            self.AII = False\n",
    "        else:\n",
    "            self.AII = True\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self):\n",
    "\n",
    "        me = \"\"\"\n",
    "        Generalized von Neumann expanding model:\n",
    "          - number of goods          : {n}\n",
    "          - number of activities     : {m}\n",
    "\n",
    "        Assumptions:\n",
    "          - AI:  every column of B has a positive entry    : {AI}\n",
    "          - AII: every row of A has a positive entry       : {AII}\n",
    "\n",
    "        \"\"\"\n",
    "        # Irreducible                                       : {irr}\n",
    "        return dedent(me.format(n=self.n, m=self.m,\n",
    "                                AI=self.AI, AII=self.AII))\n",
    "\n",
    "    def convert(self, x):\n",
    "        \"\"\"\n",
    "        Convert array_like objects (lists of lists, floats, etc.) into\n",
    "        well-formed 2D NumPy arrays\n",
    "        \"\"\"\n",
    "        return np.atleast_2d(np.asarray(x))\n",
    "\n",
    "\n",
    "    def bounds(self):\n",
    "        \"\"\"\n",
    "        Calculate the trivial upper and lower bounds for alpha (expansion rate)\n",
    "        and beta (interest factor). See the proof of Theorem 9.8 in Gale (1960)\n",
    "        \"\"\"\n",
    "\n",
    "        n, m = self.n, self.m\n",
    "        A, B = self.A, self.B\n",
    "\n",
    "        f = lambda α: ((B - α * A) @ np.ones((n, 1))).max()\n",
    "        g = lambda β: (np.ones((1, m)) @ (B - β * A)).min()\n",
    "\n",
    "        UB = fsolve(f, 1).item()  # Upper bound for α, β\n",
    "        LB = fsolve(g, 2).item()  # Lower bound for α, β\n",
    "\n",
    "        return LB, UB\n",
    "\n",
    "\n",
    "    def zerosum(self, γ, dual=False):\n",
    "        \"\"\"\n",
    "        Given gamma, calculate the value and optimal strategies of a\n",
    "        two-player zero-sum game given by the matrix\n",
    "\n",
    "                M(gamma) = B - gamma * A\n",
    "\n",
    "        Row player maximizing, column player minimizing\n",
    "\n",
    "        Zero-sum game as an LP (primal --> α)\n",
    "\n",
    "            max (0', 1) @ (x', v)\n",
    "            subject to\n",
    "            [-M', ones(n, 1)] @ (x', v)' <= 0\n",
    "            (x', v) @ (ones(m, 1), 0) = 1\n",
    "            (x', v) >= (0', -inf)\n",
    "\n",
    "        Zero-sum game as an LP (dual --> beta)\n",
    "\n",
    "            min (0', 1) @ (p', u)\n",
    "            subject to\n",
    "            [M, -ones(m, 1)] @ (p', u)' <= 0\n",
    "            (p', u) @ (ones(n, 1), 0) = 1\n",
    "            (p', u) >= (0', -inf)\n",
    "\n",
    "        Outputs:\n",
    "        --------\n",
    "        value: scalar\n",
    "            value of the zero-sum game\n",
    "\n",
    "        strategy: vector\n",
    "            if dual = False, it is the intensity vector,\n",
    "            if dual = True, it is the price vector\n",
    "        \"\"\"\n",
    "\n",
    "        A, B, n, m = self.A, self.B, self.n, self.m\n",
    "        M = B - γ * A\n",
    "\n",
    "        if dual == False:\n",
    "            # Solve the primal LP (for details see the description)\n",
    "            # (1) Define the problem for v as a maximization (linprog minimizes)\n",
    "            c = np.hstack([np.zeros(m), -1])\n",
    "\n",
    "            # (2) Add constraints :\n",
    "            # ... non-negativity constraints\n",
    "            bounds = tuple(m * [(0, None)] + [(None, None)])\n",
    "            # ... inequality constraints\n",
    "            A_iq = np.hstack([-M.T, np.ones((n, 1))])\n",
    "            b_iq = np.zeros((n, 1))\n",
    "            # ... normalization\n",
    "            A_eq = np.hstack([np.ones(m), 0]).reshape(1, m + 1)\n",
    "            b_eq = 1\n",
    "\n",
    "            res = linprog(c, A_ub=A_iq, b_ub=b_iq, A_eq=A_eq, b_eq=b_eq,\n",
    "                          bounds=bounds)\n",
    "\n",
    "        else:\n",
    "            # Solve the dual LP (for details see the description)\n",
    "            # (1) Define the problem for v as a maximization (linprog minimizes)\n",
    "            c = np.hstack([np.zeros(n), 1])\n",
    "\n",
    "            # (2) Add constraints :\n",
    "            # ... non-negativity constraints\n",
    "            bounds = tuple(n * [(0, None)] + [(None, None)])\n",
    "            # ... inequality constraints\n",
    "            A_iq = np.hstack([M, -np.ones((m, 1))])\n",
    "            b_iq = np.zeros((m, 1))\n",
    "            # ... normalization\n",
    "            A_eq = np.hstack([np.ones(n), 0]).reshape(1, n + 1)\n",
    "            b_eq = 1\n",
    "\n",
    "            res = linprog(c, A_ub=A_iq, b_ub=b_iq, A_eq=A_eq, b_eq=b_eq,\n",
    "                          bounds=bounds)\n",
    "\n",
    "        if res.status != 0 or res.x is None:\n",
    "            # LP infeasible or error\n",
    "            return np.nan, None\n",
    "\n",
    "        # Pull out the required quantities\n",
    "        value = res.x[-1]\n",
    "        strategy = res.x[:-1]\n",
    "\n",
    "        return value, strategy\n",
    "\n",
    "\n",
    "    def expansion(self, tol=1e-8, maxit=1000):\n",
    "        \"\"\"\n",
    "        The algorithm used here is described in Hamburger-Thompson-Weil\n",
    "        (1967, ECTA). It is based on a simple bisection argument and utilizes\n",
    "        the idea that for a given γ (= α or β), the matrix \"M = B - γ * A\"\n",
    "        defines a two-player zero-sum game, where the optimal strategies are\n",
    "        the (normalized) intensity and price vector.\n",
    "\n",
    "        Outputs:\n",
    "        --------\n",
    "        alpha: scalar\n",
    "            optimal expansion rate\n",
    "        \"\"\"\n",
    "\n",
    "        LB, UB = self.bounds()\n",
    "\n",
    "        for iter in range(maxit):\n",
    "\n",
    "            γ = (LB + UB) / 2\n",
    "            ZS = self.zerosum(γ=γ, dual=False)\n",
    "            V = ZS[0]     # value of the game with γ\n",
    "\n",
    "            if V >= 0:\n",
    "                LB = γ\n",
    "            else:\n",
    "                UB = γ\n",
    "\n",
    "            if abs(UB - LB) < tol:\n",
    "                γ = (UB + LB) / 2\n",
    "                x = self.zerosum(γ=γ)[1]\n",
    "                p = self.zerosum(γ=γ, dual=True)[1]\n",
    "                break\n",
    "\n",
    "        return γ, x, p\n",
    "\n",
    "    def interest(self, tol=1e-8, maxit=1000):\n",
    "        \"\"\"\n",
    "        The algorithm used here is described in Hamburger-Thompson-Weil\n",
    "        (1967, ECTA). It is based on a simple bisection argument and utilizes\n",
    "        the idea that for a given gamma (= alpha or beta),\n",
    "        the matrix \"M = B - γ * A\" defines a two-player zero-sum game,\n",
    "        where the optimal strategies are the (normalized) intensity and price\n",
    "        vector\n",
    "\n",
    "        Outputs:\n",
    "        --------\n",
    "        beta: scalar\n",
    "            optimal interest rate\n",
    "        \"\"\"\n",
    "\n",
    "        LB, UB = self.bounds()\n",
    "\n",
    "        for iter in range(maxit):\n",
    "            γ = (LB + UB) / 2\n",
    "            ZS = self.zerosum(γ=γ, dual=True)\n",
    "            V = ZS[0]\n",
    "\n",
    "            if V > 0:\n",
    "                LB = γ\n",
    "            else:\n",
    "                UB = γ\n",
    "\n",
    "            if abs(UB - LB) < tol:\n",
    "                γ = (UB + LB) / 2\n",
    "                p = self.zerosum(γ=γ, dual=True)[1]\n",
    "                x = self.zerosum(γ=γ)[1]\n",
    "                break\n",
    "\n",
    "        return γ, x, p\n",
    "    \n",
    "def compute_von_neumann_alpha_beta(S_plus, S_minus, tol=1e-8):\n",
    "    \"\"\"\n",
    "    Compute von Neumann alpha (expansion) and beta (interest) for the network.\n",
    "    Returns alpha, beta.\n",
    "    \"\"\"\n",
    "    # Build A, B for Neumann: A = input = S_minus^T, B = output = S_plus^T\n",
    "    A = S_minus.T\n",
    "    B = S_plus.T\n",
    "    model = Neumann(A, B)\n",
    "    alpha, _, _ = model.expansion(tol=tol)\n",
    "    beta, _, _  = model.interest(tol=tol)\n",
    "    return alpha, beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4421d-2dbd-4f92-a778-ae710e8ff006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d38e84fb-ccca-4561-8a85-533a87912ca0",
   "metadata": {},
   "source": [
    "# Construct Kinetic Constants and Initial Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "609109fb-472c-41e5-8661-82826e22b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mu(mu0, Z):\n",
    "    \n",
    "    if Z <= 0:\n",
    "        raise ValueError\n",
    "    \n",
    "    return mu0 + math.log(Z)\n",
    "\n",
    "def Construct_Kinetics(N_X, N_Y, N_R, S_plus, S_minus, degradation):\n",
    "    X0 = [2.0 * random.uniform(0.95, 1.05) for _ in range(N_X)]\n",
    "    Y0 = [0.01 * random.uniform(0.95, 1.05) for _ in range(N_Y)]\n",
    "    ini_concentration = np.concatenate([X0, Y0])\n",
    "    kf = [random.uniform(1.95, 2.05) for _ in range(N_R)]\n",
    "    # confine the chemical potentials of species X\n",
    "    mu_0_X = [random.uniform(-1, 1) for _ in range(N_X)]\n",
    "    mu_X_actual = np.array([compute_mu(mu_0_X[i], X0[i]) for i in range(N_X)])\n",
    "    mu_0_Y = [random.uniform(-1, 1) for _ in range(N_Y)]\n",
    "    mu_0 = mu_0_X + mu_0_Y\n",
    "    mu_0_vector = np.array(mu_0).reshape(-1, 1)\n",
    "    DeltaG0 = np.dot(S_plus.T, mu_0_vector).flatten() - np.dot(S_minus.T, mu_0_vector).flatten()\n",
    "    print(f\"DeltaG0={DeltaG0}\")\n",
    "    print(f\"kr/kf:{np.exp(DeltaG0)}\")\n",
    "    kr = kf * np.exp(DeltaG0)\n",
    "\n",
    "    # degradation coefficient\n",
    "    kd = None\n",
    "    if degradation:\n",
    "        kd = 0.01*np.array([random.uniform(0.95, 1.05) for _ in range(N_Y)])\n",
    "    # try to change some forms\n",
    "\n",
    "    return ini_concentration, kf, kr, kd, mu_X_actual, mu_0_vector, DeltaG0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a032be3-4bc2-46fe-95f2-b122ab05b902",
   "metadata": {},
   "source": [
    "# Dynamical Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474ddfb-48ff-4ec5-83f5-42859cba5d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Version 2: Self adaptation simulation \n",
    "Without fixing a total time length, checking the concentration change dynamically, \n",
    "if the concentration maintains the same for a set time length, regard the system entersteady state\n",
    "'''\n",
    "def Solve_Concentration_SS(\n",
    "    S_minus, S_plus, X0, Y0, N_X, N_Y, N_R,\n",
    "    kf, kr, kd, law,\n",
    "    dt=1e-2, tol_ss=1e-5, consec_steps=100,\n",
    "    rtol=1e-2, atol=1e-5):\n",
    "    \"\"\"\n",
    "    ntegrate iteratively with a fixed step size dt until the change in Y over consecutive consec_steps steps is < tol_ss.\n",
    "    Returns:\n",
    "      t_hist:    shape (nt,)\n",
    "      Y_hist:    shape (nt, N_Y)\n",
    "      X_hist:    shape (nt, N_X)\n",
    "    \"\"\"\n",
    "    # ODE\n",
    "    def dydt(t, Y):\n",
    "        curr = np.zeros(N_R)\n",
    "        ratef = np.ones(N_R) if law==\"MM\" else kf.copy()\n",
    "        rater = kr.copy()\n",
    "        X_Y = np.concatenate((X0, Y))\n",
    "        for l in range(N_R):\n",
    "            # forward\n",
    "            prod = np.prod([s**p for s,p in zip(X_Y, S_minus[:,l])])\n",
    "            ratef[l] = prod/(kf[l]+prod) if law==\"MM\" else kf[l]*prod\n",
    "            # reverse\n",
    "            term = 1.0\n",
    "            for s,p in zip(X_Y, S_plus[:,l]):\n",
    "                term *= min(s**p, 1e10)\n",
    "            rater[l] *= term\n",
    "            curr[l] = ratef[l] - rater[l]\n",
    "        if kd is not None:\n",
    "            curr -= np.maximum(kd * Y, 0)\n",
    "        return ((S_plus - S_minus)[N_X:,:] @ curr)\n",
    "\n",
    "    t = 0.0\n",
    "    Y = Y0.copy()\n",
    "    t_hist = [t]\n",
    "    Y_hist = [Y.copy()]\n",
    "    X_hist = [X0.copy()]\n",
    "\n",
    "    small_count = 0\n",
    "    # prevent infinite loops.\n",
    "    max_steps = 500000  \n",
    "    for step in range(max_steps):\n",
    "        # take short step integration among [t, t+dt]\n",
    "        sol = solve_ivp(\n",
    "            dydt, [t, t+dt], Y, method=\"LSODA\",\n",
    "            max_step=dt, rtol=rtol, atol=atol\n",
    "        )\n",
    "        Y_new = sol.y[:,-1]\n",
    "        t = sol.t[-1]\n",
    "\n",
    "        # record\n",
    "        t_hist.append(t)\n",
    "        Y_hist.append(Y_new.copy())\n",
    "        X_hist.append(X0.copy())\n",
    "\n",
    "        # Check new concentration difference\n",
    "        if np.max(np.abs(Y_new - Y)) < tol_ss:\n",
    "            small_count += 1\n",
    "        else:\n",
    "            small_count = 0\n",
    "\n",
    "        # Exit if the condition is met for consec_steps consecutive steps\n",
    "        if small_count >= consec_steps:\n",
    "            break\n",
    "\n",
    "        Y = Y_new\n",
    "\n",
    "    return np.array(t_hist), np.vstack(Y_hist), np.vstack(X_hist)\n",
    "\n",
    "def Solve_Concentration(\n",
    "    S_minus, S_plus, X0, Y0,\n",
    "    N_X, N_Y, N_R,\n",
    "    kf, kr, kd,\n",
    "    law, dt=1e-2, tol_ss=1e-5, consec_steps=100,\n",
    "    rtol=1e-2, atol=1e-5):\n",
    "\n",
    "    t_hist, Y_hist, X_hist = Solve_Concentration_SS(\n",
    "        S_minus, S_plus, X0, Y0,\n",
    "        N_X, N_Y, N_R,\n",
    "        kf, kr, kd, law,\n",
    "        dt=dt,\n",
    "        tol_ss=tol_ss,\n",
    "        consec_steps=consec_steps,\n",
    "        rtol=rtol,\n",
    "        atol=atol\n",
    "    )\n",
    "\n",
    "    # Wrapped to have the same sol interface as the old version.\n",
    "    sol = SimpleNamespace(\n",
    "        t = np.array(t_hist),       \n",
    "        y = np.array(Y_hist).T       \n",
    "    )\n",
    "\n",
    "    X_history = np.array(X_hist)\n",
    "\n",
    "    return sol, X_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fea8efb-ec51-4124-885e-0278311aa4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_affinity_and_fluxes(S_minus, S_plus, X0, Y_vec, N_X, N_Y, N_R, kf, kr, law):\n",
    "    \"\"\"\n",
    "    Given X0, Y_vec at specific time point, compute net flux current and affinity\n",
    "    Return: Aff (N_R,), curr (N_R,)\n",
    "    \"\"\"\n",
    "\n",
    "    curr = np.zeros(N_R)\n",
    "    Aff  = np.zeros(N_R)\n",
    "    ratef = np.ones(N_R) if law==\"MM\" else kf.copy()\n",
    "    rater = deepcopy(kr)\n",
    "    X_Y = np.concatenate((X0, Y_vec))\n",
    "\n",
    "    for l in range(N_R):\n",
    "        prod = np.prod([s**p for s, p in zip(X_Y, S_minus[:, l])])\n",
    "        ratef[l] = prod/(kf[l]+prod) if law==\"MM\" else kf[l]*prod\n",
    "        term = 1.0\n",
    "        for s, p in zip(X_Y, S_plus[:, l]):\n",
    "            term *= min(s**p, 1e10)\n",
    "        rater[l] *= term\n",
    "\n",
    "        curr[l] = ratef[l] - rater[l]\n",
    "        if not np.isfinite(curr[l]):\n",
    "            curr[l] = 0.0\n",
    "\n",
    "        # affinity\n",
    "        if rater[l] != 0 and ratef[l] >= 0:\n",
    "            Aff[l] = np.log(ratef[l]/rater[l])\n",
    "        else:\n",
    "            Aff[l] = np.nan\n",
    "\n",
    "    return Aff, curr\n",
    "\n",
    "def compute_energy_flow(curr, Aff):\n",
    "    \"\"\" energy flow for each reaction = curr * Aff \"\"\"\n",
    "    return curr * Aff\n",
    "\n",
    "\n",
    "def compute_entropy_production_rate(curr, Aff):\n",
    "    \"\"\"Entropy production rate for whole system = Sigma (curr * Aff) \"\"\"\n",
    "    return np.dot(curr, Aff)\n",
    "\n",
    "\n",
    "def compute_chemical_work(Stot, curr, N_X, mu_X_actual):\n",
    "    \"\"\"\n",
    "    Chemical Work = mu_actual * Curr_ext\n",
    "    Curr_ext[i] = - Sigma_j (Stot[i,j] * curr[j])\n",
    "    \"\"\"\n",
    "    Curr_ext = - np.dot(Stot[N_X, :], curr)\n",
    "    return np.dot(mu_X_actual, Curr_ext)\n",
    "\n",
    "\n",
    "def Dynamic_Simulation(S_minus: np.ndarray,\n",
    "                       S_plus: np.ndarray,\n",
    "                       Stot: np.ndarray,\n",
    "                       X0: np.ndarray,\n",
    "                       Y0: np.ndarray,\n",
    "                       N_X: int,\n",
    "                       N_Y: int,\n",
    "                       N_R: int,\n",
    "                       kf: np.ndarray,\n",
    "                       kr: np.ndarray,\n",
    "                       kd,\n",
    "                       mu_X_actual: np.ndarray,\n",
    "                       law: str):\n",
    "    \"\"\"\n",
    "    adaptive step size concentration simulation and calculate thermodynamic quantities for the entire time series.\n",
    "\n",
    "    Returns:\n",
    "      sol_t, sol_y, flux_ts, affinity_ts, energy_flow_ts, entropy_prod_ts, chemical_work_ts\n",
    "    \"\"\"\n",
    "    sol, X_hist = Solve_Concentration(\n",
    "        S_minus, S_plus, X0, Y0,\n",
    "        N_X, N_Y, N_R,\n",
    "        kf, kr, kd,\n",
    "        law\n",
    "    )\n",
    "    sol_t = sol.t\n",
    "    sol_y = sol.y.T  # (nt, N_Y)\n",
    "\n",
    "    # Compute Thermodynamic quantities\n",
    "    flux_list = []\n",
    "    aff_list = []\n",
    "    ef_list = []\n",
    "    ep_list = []\n",
    "    cw_list = []\n",
    "    for Y_vec, X_vec in zip(sol_y, X_hist):\n",
    "        Aff, curr = compute_affinity_and_fluxes(\n",
    "            S_minus, S_plus,\n",
    "            X0=X_vec, Y_vec=Y_vec,\n",
    "            N_X=N_X, N_Y=N_Y, N_R=N_R,\n",
    "            kf=kf, kr=kr,\n",
    "            law=law\n",
    "        )\n",
    "        flux_list.append(curr)\n",
    "        aff_list.append(Aff)\n",
    "        ef_list.append(compute_energy_flow(curr, Aff))\n",
    "        ep_list.append(compute_entropy_production_rate(curr, Aff))\n",
    "        cw_list.append(compute_chemical_work(Stot, curr, N_X, mu_X_actual))\n",
    "\n",
    "    flux_ts = np.array(flux_list)\n",
    "    affinity_ts = np.array(aff_list)\n",
    "    energy_flow_ts = np.array(ef_list)\n",
    "    entropy_prod_ts = np.array(ep_list)\n",
    "    chemical_work_ts = np.array(cw_list)\n",
    "\n",
    "    return sol_t, sol_y, flux_ts, affinity_ts, energy_flow_ts, entropy_prod_ts, chemical_work_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2012b6-578a-4761-989d-215fcff96eb2",
   "metadata": {},
   "source": [
    "# Steady State Concentration distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbc5f118-c4e7-4649-80ca-e94430cdddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shannon_entropy(Y: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Given a set of non-negative Y concentrations, \n",
    "    first normalize them as p_i = Y_i / sum(Y_i), \n",
    "    then calculate the Shannon entropy H = -sum_i p_i * log(p_i). \n",
    "    If sum(Y) == 0, return 0.\n",
    "    \"\"\"\n",
    "    Y = np.asarray(Y, float)\n",
    "    total = Y.sum()\n",
    "    if total <= 0:\n",
    "        return 0.0\n",
    "    p = Y / total\n",
    "\n",
    "    p_nonzero = p[p > 0]\n",
    "    return -np.sum(p_nonzero * np.log(p_nonzero))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c20f29-8926-47a4-9cdf-5596479cf87a",
   "metadata": {},
   "source": [
    "# Lyapunov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84761a86-03f4-4592-8ac7-fbbed288e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_core_jacobian_max_eig_at_time(core, S_minus, S_plus,\n",
    "                                          X0, Y0, kf, kr, kd,\n",
    "                                          N_X, law=\"mass_action\",\n",
    "                                          t_target=1.0, eps=1e-6):\n",
    "    \"\"\"\n",
    "    For a single core, compute numeric Jacobian of dY/dt at Y0 and return max real eigenvalue.\n",
    "    \"\"\"\n",
    "    kf = np.asarray(kf, float)\n",
    "    kr = np.asarray(kr, float)\n",
    "    if kd is not None:\n",
    "        kd = np.asarray(kd, float)\n",
    "\n",
    "    # extract sub‐indices\n",
    "    sp_idx = core['species']\n",
    "    rx_idx = core['reactions']\n",
    "\n",
    "    S_minus_sub = S_minus[np.ix_(sp_idx, rx_idx)]\n",
    "    S_plus_sub  = S_plus[np.ix_(sp_idx, rx_idx)]\n",
    "    kf_sub = kf[rx_idx]\n",
    "    kr_sub = kr[rx_idx]\n",
    "\n",
    "    # build Y‐sub vector\n",
    "    Y_idx = [i - N_X for i in sp_idx if i >= N_X]\n",
    "    Y0_sub = np.asarray(Y0, float)[Y_idx]\n",
    "    kd_sub = None if kd is None else kd[Y_idx]\n",
    "\n",
    "    # f_sub\n",
    "    def f_sub(Y_sub):\n",
    "        curr = compute_net_flux(\n",
    "            S_minus_sub, S_plus_sub, X0, Y_sub,\n",
    "            kf_sub, kr_sub, law, kd_sub\n",
    "        )\n",
    "\n",
    "        # row_count = len(Y_idx)，col_count = len(rx_idx)\n",
    "        Sdiff = (S_plus_sub - S_minus_sub)[len(sp_idx)-len(Y_idx):, :]\n",
    "        return Sdiff @ curr\n",
    "\n",
    "    # Integral\n",
    "    sol = solve_ivp(lambda t, y: f_sub(y),\n",
    "                    [0, t_target], y0=Y0_sub,\n",
    "                    method=\"LSODA\", rtol=1e-6, atol=1e-8, max_step=1e-2)\n",
    "    Y_tt = sol.y[:, -1]\n",
    "\n",
    "    n = Y_tt.size\n",
    "    J = np.zeros((n, n))\n",
    "    f0 = f_sub(Y_tt)\n",
    "    for j in range(n):\n",
    "        Yp = Y_tt.copy()\n",
    "        Yp[j] += eps\n",
    "        J[:, j] = (f_sub(Yp) - f0) / eps\n",
    "\n",
    "    eigs = np.linalg.eigvals(J)\n",
    "    return np.max(eigs.real), J, eigs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387f064-f867-41b4-a76f-aea784301d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c460d9c0-5f82-4521-9b66-9d73ac6dc548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69132fa-511f-4441-88ca-f98842c473e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939c6c0-66f5-49e9-84f0-e19d904f358e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43504627-4160-4d72-85f3-c1f40d42f694",
   "metadata": {},
   "source": [
    "# Entropy Production Rate of Each Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9616a-4b0e-46ab-af08-823957344092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compute_Core_EPR(energy_flow: np.ndarray,\n",
    "                                 cores: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each core, sum the energy_flow of all reactions on that core at each point in time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    energy_flow : np.ndarray, shape (nt, N_R)\n",
    "        \n",
    "    cores : list of dict\n",
    "        [{'core': str, 'reactions': [r0, r1, ...]}, ...]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Row index is the time step (0..nt-1), and the columns are the core labels.\n",
    "    \"\"\"\n",
    "    nt, _ = energy_flow.shape\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        np.zeros((nt, len(cores))),\n",
    "        columns=[c['core'] for c in cores]\n",
    "    )\n",
    "    # For each core, sum the corresponding reaction column.\n",
    "    for c in cores:\n",
    "        label = c['core']\n",
    "        rxns = c['reactions']\n",
    "\n",
    "        df[label] = energy_flow[:, rxns].sum(axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f4731-c86e-4bb1-80d1-adc10f16905b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "445a0bda-52d1-4d1c-a750-b449cd5ab66a",
   "metadata": {},
   "source": [
    "# Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e342a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_network_visualization(G, pos, core_species_colors, core_nodes, N_RY, sol, Energy_Flow, NetFlux_values, output_dir, realization_index, snapshot_interval=100):\n",
    "    \"\"\"\n",
    "    Dynamic network visualization:\n",
    "    Update the size of nodes in the reaction network based on simulation data (time series, energy flow, net flux) (e.g., changes in Y species concentration);\n",
    "    Determine edge width and arrow color based on current frame's energy flow and net flux;\n",
    "    Generate an animation and save it as an MP4 file.\n",
    "    \n",
    "    Parameters:\n",
    "    G: networkx graph object (typically a MultiDiGraph)\n",
    "    pos: Dictionary of node positions (node -> (x, y))\n",
    "    core_species_colors: dict, Color mapping for core species, e.g., {\"X1\": \"red\"}\n",
    "    core_nodes: set, Set of all core nodes (generally the set of keys from core_species_colors)\n",
    "    N_RY: Total number of reactions (e.g., the number of reactions in the entire system)\n",
    "    sol: Simulation results object, required to contain attributes sol.t (time array) and sol.y (state matrix, assuming rows correspond to Y species)\n",
    "    Energy_Flow: Array of shape (len(sol.t), N_RY) representing energy flow data\n",
    "    NetFlux_values: Array of shape (len(sol.t), N_RY) representing net flux data (positive and negative values may occur)\n",
    "    output_dir: Output directory for saving the animation\n",
    "    realization_index: Index number of the current simulation instance (used for file naming)\n",
    "    snapshot_interval: Interval index for updating animation frames (default: 100)\n",
    "        \n",
    "    Returns:\n",
    "    ani: Dynamic animation\n",
    "    \n",
    "    \"\"\"\n",
    "    # Calculate the coordinate range\n",
    "    x_vals = [p[0] for p in pos.values()]\n",
    "    y_vals = [p[1] for p in pos.values()]\n",
    "    x_margin = (max(x_vals) - min(x_vals)) * 0.2\n",
    "    y_margin = (max(y_vals) - min(y_vals)) * 0.2\n",
    "    x_lim = (min(x_vals) - x_margin, max(x_vals) + x_margin)\n",
    "    y_lim = (min(y_vals) - y_margin, max(y_vals) + y_margin)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    frame_indices = list(range(0, len(sol.t), snapshot_interval))\n",
    "\n",
    "    def update_frame(i):\n",
    "        ax.clear()\n",
    "        t_current = sol.t[i]\n",
    "        ax.set_xlim(x_lim)\n",
    "        ax.set_ylim(y_lim)\n",
    "        # Update node size based on the node's category: fixed size or proportional to concentration.\n",
    "        core_nodes_dyn = []\n",
    "        non_core_nodes_dyn = []\n",
    "        core_sizes = []\n",
    "        non_core_sizes = []\n",
    "        for node in G.nodes():\n",
    "            if node.startswith(\"X\"):\n",
    "                size_val = 500  # Fixed species X size\n",
    "            else:\n",
    "                try:\n",
    "                    # Assuming a node name like \"Y1\", its index would be 0.\n",
    "                    idx = int(node[1:]) - 1\n",
    "                    size_val = sol.y[idx, i] * 3000  # Adjust magnification factor based on concentration.\n",
    "                except:\n",
    "                    size_val = 500\n",
    "            if node in core_nodes:\n",
    "                core_nodes_dyn.append(node)\n",
    "                core_sizes.append(size_val)\n",
    "            else:\n",
    "                non_core_nodes_dyn.append(node)\n",
    "                non_core_sizes.append(size_val)\n",
    "        # Draw core nodes (squares with black borders)\n",
    "        if core_nodes_dyn:\n",
    "            nx.draw_networkx_nodes(G, pos,\n",
    "                                   nodelist=core_nodes_dyn,\n",
    "                                   node_size=core_sizes,\n",
    "                                   node_color=[core_species_colors.get(n, \"lightcoral\") for n in core_nodes_dyn],\n",
    "                                   node_shape='s',\n",
    "                                   edgecolors='black',\n",
    "                                   linewidths=2,\n",
    "                                   ax=ax)\n",
    "        # Draw non-core nodes (circles)）\n",
    "        if non_core_nodes_dyn:\n",
    "            non_core_colors_dyn = []\n",
    "            for node in non_core_nodes_dyn:\n",
    "                if node.startswith(\"X\"):\n",
    "                    non_core_colors_dyn.append(\"lightgreen\")\n",
    "                else:\n",
    "                    non_core_colors_dyn.append(\"lightcoral\")\n",
    "            nx.draw_networkx_nodes(G, pos,\n",
    "                                   nodelist=non_core_nodes_dyn,\n",
    "                                   node_size=non_core_sizes,\n",
    "                                   node_color=non_core_colors_dyn,\n",
    "                                   node_shape='o',\n",
    "                                   ax=ax)\n",
    "        nx.draw_networkx_labels(G, pos, ax=ax)\n",
    "        # Dynamically update edges based on the energy flow and net flow of each reaction\n",
    "        for j in range(N_RY):\n",
    "            reac_name = f\"Reaction {j+1}\"\n",
    "            energy_val = Energy_Flow[i, j]\n",
    "            netflux_val = NetFlux_values[i, j]\n",
    "            edge_width = max(0.5, abs(energy_val) * 5)\n",
    "            if netflux_val > 0.1:\n",
    "                arrow_color = \"red\"\n",
    "            elif netflux_val < -0.1:\n",
    "                arrow_color = \"blue\"\n",
    "            else:\n",
    "                arrow_color = \"gray\"\n",
    "            # For MultiDiGraph, extract (u, v, k) tuples: note keys=True\n",
    "            edge_list = [(u, v, k) for u, v, k, data in G.edges(keys=True, data=True) if data.get(\"reaction\", \"\") == reac_name]\n",
    "            if edge_list:\n",
    "                for (u, v, k) in edge_list:\n",
    "                    nx.draw_networkx_edges(G, pos, edgelist=[(u, v)], ax=ax,\n",
    "                                           width=edge_width, arrowstyle='-|>',\n",
    "                                           arrowsize=15, edge_color=arrow_color)\n",
    "        ax.set_title(f\"Dynamic Reaction Network at t = {t_current:.2f}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update_frame, frames=frame_indices, interval=200, repeat=True)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    dyn_viz_path = os.path.join(output_dir, f\"Dynamic_Network_Realization_{realization_index}.mp4\")\n",
    "    ani.save(dyn_viz_path, writer='ffmpeg', dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"Dynamic network visualization saved to {dyn_viz_path}\")\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa3dda-5c63-49d6-a58f-09f0e9a4036d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "347966d7-96ec-4ff5-add5-72d0eacff5a3",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d54e6b92-c3d7-4b10-abb6-49bcf230a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    # directory\n",
    "    def __init__(self, base_dir: str):\n",
    "        self.base = Path(base_dir)\n",
    "        self.base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self._index = []\n",
    "\n",
    "    def save_run(self, run_idx: int,\n",
    "                 S_minus: np.ndarray,\n",
    "                 S_plus: np.ndarray,\n",
    "                 flux: np.ndarray,\n",
    "                 affinity: np.ndarray,\n",
    "                 energy_flow: np.ndarray,\n",
    "                 entropy_production_rate: np.ndarray,\n",
    "                 chemical_work: np.ndarray,\n",
    "                 sol_t: np.ndarray,\n",
    "                 sol_y: np.ndarray,\n",
    "                 mgf: float,\n",
    "                 vn_alpha: float,\n",
    "                 vn_beta: float,\n",
    "                 H: float):\n",
    "        \"\"\"Create a new subdirectory for each successful simulation\"\"\"\n",
    "        sub = self.base / f\"run_{run_idx:04d}\"\n",
    "        sub.mkdir(exist_ok=True)\n",
    "\n",
    "        # S matrix\n",
    "        np.save(sub / \"S_minus.npy\", S_minus)\n",
    "        np.save(sub / \"S_plus.npy\",  S_plus)\n",
    "\n",
    "        # ODE solution\n",
    "        np.save(sub / \"t.npy\", sol_t)\n",
    "        np.save(sub / \"Y.npy\", sol_y)\n",
    "        np.save(sub / \"flux.npy\", flux)\n",
    "        np.save(sub / \"affinity.npy\", affinity)\n",
    "        np.save(sub / \"entropy_production_rate\", entropy_production_rate)\n",
    "        np.save(sub / \"energy_flow\", energy_flow)\n",
    "        np.save(sub / \"chemical_work\", chemical_work)\n",
    "\n",
    "        # Network parameter\n",
    "        with open(sub / \"stats.json\", \"w\") as f:\n",
    "            json.dump({\n",
    "                \"mgf\": mgf,\n",
    "                \"vn_alpha\": vn_alpha,\n",
    "                \"vn_beta\": vn_beta,\n",
    "                \"shannon_entropy\": H\n",
    "            }, f, indent=2)\n",
    "\n",
    "        # renew index\n",
    "        self._index.append({\n",
    "            \"run\": run_idx,\n",
    "            \"path\": str(sub),\n",
    "            \"mgf\": mgf,\n",
    "            \"vn_alpha\": vn_alpha,\n",
    "            \"vn_beta\": vn_beta,\n",
    "            \"shannon_entropy\": H\n",
    "        })\n",
    "\n",
    "    def finalize(self):\n",
    "        \"\"\"generate a master index table to make it easier for pandas to read\"\"\"\n",
    "        df = pd.DataFrame(self._index)\n",
    "        df.to_csv(self.base / \"index_summary.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ee6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1aa777c-4e07-4abd-90c7-1e29d832bf86",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd38fe8e-bf79-4af3-8df5-c9751bd56bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Stot:\n",
      "   1  2  3  4  5  6  7  8\n",
      "1 -1  1  0  0  0  0  0  0\n",
      "2  0  0 -1  0  0  1  0  0\n",
      "3  0  0  0 -1  0 -1  0  0\n",
      "4  1  0 -1  0  1  0 -1 -2\n",
      "5  0  0  1  0  1  1 -1  0\n",
      "6 -1  1  0 -2 -1 -1  1  0\n",
      "7  0  0  0  0  0  0  0  1\n",
      "8 -1  1  0  0  0 -1  0  0\n",
      "9  0 -1  1  1  1  1  1 -1\n",
      "\n",
      "S_plus:\n",
      "   1  2  3  4  5  6  7  8\n",
      "1  0  1  0  0  0  0  0  0\n",
      "2  0  0  0  0  0  1  0  0\n",
      "3  0  0  0  0  0  0  0  0\n",
      "4  1  0  0  0  1  0  0  0\n",
      "5  0  0  1  0  1  1  0  0\n",
      "6  0  1  0  0  0  0  1  0\n",
      "7  0  0  0  0  0  0  0  1\n",
      "8  0  1  0  0  0  0  0  0\n",
      "9  0  0  1  1  1  1  1  0\n",
      "\n",
      "S_minus:\n",
      "   1  2  3  4  5  6  7  8\n",
      "1  1  0  0  0  0  0  0  0\n",
      "2  0  0  1  0  0  0  0  0\n",
      "3  0  0  0  1  0  1  0  0\n",
      "4  0  0  1  0  0  0  1  2\n",
      "5  0  0  0  0  0  0  1  0\n",
      "6  1  0  0  2  1  1  0  0\n",
      "7  0  0  0  0  0  0  0  0\n",
      "8  1  0  0  0  0  1  0  0\n",
      "9  0  1  0  0  0  0  0  1\n",
      "Matrix Stot:\n",
      "   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "1   0   0   0   0   0   0   0   0   0   1   0   0   0   1\n",
      "2   0   0  -1   0   0   0   0   0   0   0   0   0   0   0\n",
      "3   0   0   1   0   0   1  -1   0  -1  -1  -1   0   0   0\n",
      "4   0   1   0   0   0   0   0  -2   0   0   1   0   0   0\n",
      "5  -1   1   0   0   0   0   0   1   0   0  -1  -1   0   0\n",
      "6   2  -1  -1  -1   1  -1  -1   1   2   0  -1  -1  -1   0\n",
      "7  -1   0  -1   1  -1   2   1   0  -1   2   1  -1   0   2\n",
      "8  -1   1   1  -1   0  -1   0  -1   0  -1   0   1   1  -1\n",
      "\n",
      "S_plus:\n",
      "   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "1   0   0   0   0   0   0   0   0   0   1   0   0   0   1\n",
      "2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "3   0   0   1   0   0   1   0   0   0   0   0   0   0   0\n",
      "4   0   1   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "5   0   1   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "6   2   0   0   0   1   0   0   1   2   0   0   0   0   0\n",
      "7   0   0   0   1   0   2   1   0   0   2   1   0   0   2\n",
      "8   0   1   1   0   0   0   0   0   0   0   0   1   1   0\n",
      "\n",
      "S_minus:\n",
      "   1   2   3   4   5   6   7   8   9   10  11  12  13  14\n",
      "1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "2   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "3   0   0   0   0   0   0   1   0   1   1   1   0   0   0\n",
      "4   0   0   0   0   0   0   0   2   0   0   0   0   0   0\n",
      "5   1   0   0   0   0   0   0   0   0   0   1   1   0   0\n",
      "6   0   1   1   1   0   1   1   0   0   0   1   1   1   0\n",
      "7   1   0   1   0   1   0   0   0   1   0   0   1   0   0\n",
      "8   1   0   0   1   0   1   0   1   0   1   0   0   0   1\n",
      "DeltaG0=[ 3.5464153  -2.69753617 -0.55895807 -1.49717633  1.79628044 -2.89791107\n",
      " -1.32611997  2.47428832  3.13214707 -1.06686631 -1.68819671  0.35108859\n",
      " -1.16481027 -1.53702678]\n",
      "kr/kf:[34.68874553  0.0673713   0.57180453  0.2237611   6.02718724  0.05513828\n",
      "  0.26550543 11.87325415 22.9231443   0.34408509  0.18485257  1.42061317\n",
      "  0.31198185  0.21501945]\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n",
      "Set parameter TimeLimit to value 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_13612\\1806161150.py:99: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  LB = fsolve(g, 2).item()  # Lower bound for α, β\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 98\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished simulation of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_networks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m networks. Results in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 98\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[17], line 45\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(num_networks, output_dir)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Dynamic_Simulation\u001b[39;00m\n\u001b[0;32m     44\u001b[0m sol_t, sol_y, flux_ts, affinity_ts, energy_flow_ts, entropy_prod_ts, chemical_work_ts \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m---> 45\u001b[0m     Dynamic_Simulation(\n\u001b[0;32m     46\u001b[0m         S_minus, S_plus, Stot,\n\u001b[0;32m     47\u001b[0m         X0, Y0, N_X, N_Y, N_R,\n\u001b[0;32m     48\u001b[0m         kf, kr, kd,\n\u001b[0;32m     49\u001b[0m         mu_X_actual,\n\u001b[0;32m     50\u001b[0m         law\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m     )\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Compute Shannon entropy\u001b[39;00m\n\u001b[0;32m     54\u001b[0m H \u001b[38;5;241m=\u001b[39m compute_shannon_entropy(sol_y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[14], line 71\u001b[0m, in \u001b[0;36mDynamic_Simulation\u001b[1;34m(S_minus, S_plus, Stot, X0, Y0, N_X, N_Y, N_R, kf, kr, kd, mu_X_actual, law)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mDynamic_Simulation\u001b[39m(S_minus: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m     53\u001b[0m                        S_plus: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m     54\u001b[0m                        Stot: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m                        mu_X_actual: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m     64\u001b[0m                        law: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    adaptive step size concentration simulation and calculate thermodynamic quantities for the entire time series.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m      sol_t, sol_y, flux_ts, affinity_ts, energy_flow_ts, entropy_prod_ts, chemical_work_ts\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     sol, X_hist \u001b[38;5;241m=\u001b[39m Solve_Concentration(\n\u001b[0;32m     72\u001b[0m         S_minus, S_plus, X0, Y0,\n\u001b[0;32m     73\u001b[0m         N_X, N_Y, N_R,\n\u001b[0;32m     74\u001b[0m         kf, kr, kd,\n\u001b[0;32m     75\u001b[0m         law\n\u001b[0;32m     76\u001b[0m     )\n\u001b[0;32m     77\u001b[0m     sol_t \u001b[38;5;241m=\u001b[39m sol\u001b[38;5;241m.\u001b[39mt\n\u001b[0;32m     78\u001b[0m     sol_y \u001b[38;5;241m=\u001b[39m sol\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mT  \u001b[38;5;66;03m# (nt, N_Y)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 82\u001b[0m, in \u001b[0;36mSolve_Concentration\u001b[1;34m(S_minus, S_plus, X0, Y0, N_X, N_Y, N_R, kf, kr, kd, law, dt, tol_ss, consec_steps, rtol, atol)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSolve_Concentration\u001b[39m(\n\u001b[0;32m     76\u001b[0m     S_minus, S_plus, X0, Y0,\n\u001b[0;32m     77\u001b[0m     N_X, N_Y, N_R,\n\u001b[0;32m     78\u001b[0m     kf, kr, kd,\n\u001b[0;32m     79\u001b[0m     law, dt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m, tol_ss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, consec_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     80\u001b[0m     rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m):\n\u001b[1;32m---> 82\u001b[0m     t_hist, Y_hist, X_hist \u001b[38;5;241m=\u001b[39m Solve_Concentration_SS(\n\u001b[0;32m     83\u001b[0m         S_minus, S_plus, X0, Y0,\n\u001b[0;32m     84\u001b[0m         N_X, N_Y, N_R,\n\u001b[0;32m     85\u001b[0m         kf, kr, kd, law,\n\u001b[0;32m     86\u001b[0m         dt\u001b[38;5;241m=\u001b[39mdt,\n\u001b[0;32m     87\u001b[0m         tol_ss\u001b[38;5;241m=\u001b[39mtol_ss,\n\u001b[0;32m     88\u001b[0m         consec_steps\u001b[38;5;241m=\u001b[39mconsec_steps,\n\u001b[0;32m     89\u001b[0m         rtol\u001b[38;5;241m=\u001b[39mrtol,\n\u001b[0;32m     90\u001b[0m         atol\u001b[38;5;241m=\u001b[39matol\n\u001b[0;32m     91\u001b[0m     )\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# Wrapped to have the same sol interface as the old version.\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     sol \u001b[38;5;241m=\u001b[39m SimpleNamespace(\n\u001b[0;32m     95\u001b[0m         t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(t_hist),       \n\u001b[0;32m     96\u001b[0m         y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Y_hist)\u001b[38;5;241m.\u001b[39mT       \n\u001b[0;32m     97\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[8], line 49\u001b[0m, in \u001b[0;36mSolve_Concentration_SS\u001b[1;34m(S_minus, S_plus, X0, Y0, N_X, N_Y, N_R, kf, kr, kd, law, dt, tol_ss, consec_steps, rtol, atol)\u001b[0m\n\u001b[0;32m     46\u001b[0m max_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500000\u001b[39m  \n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_steps):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# take short step integration among [t, t+dt]\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     sol \u001b[38;5;241m=\u001b[39m solve_ivp(\n\u001b[0;32m     50\u001b[0m         dydt, [t, t\u001b[38;5;241m+\u001b[39mdt], Y, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSODA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     51\u001b[0m         max_step\u001b[38;5;241m=\u001b[39mdt, rtol\u001b[38;5;241m=\u001b[39mrtol, atol\u001b[38;5;241m=\u001b[39matol\n\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     53\u001b[0m     Y_new \u001b[38;5;241m=\u001b[39m sol\u001b[38;5;241m.\u001b[39my[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     54\u001b[0m     t \u001b[38;5;241m=\u001b[39m sol\u001b[38;5;241m.\u001b[39mt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\scipy\\integrate\\_ivp\\ivp.py:655\u001b[0m, in \u001b[0;36msolve_ivp\u001b[1;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)\u001b[0m\n\u001b[0;32m    653\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 655\u001b[0m     message \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m solver\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinished\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    658\u001b[0m         status \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\scipy\\integrate\\_ivp\\base.py:197\u001b[0m, in \u001b[0;36mOdeSolver.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt\n\u001b[1;32m--> 197\u001b[0m     success, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_impl()\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\scipy\\integrate\\_ivp\\lsoda.py:161\u001b[0m, in \u001b[0;36mLSODA._step_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m itask \u001b[38;5;241m=\u001b[39m integrator\u001b[38;5;241m.\u001b[39mcall_args[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    160\u001b[0m integrator\u001b[38;5;241m.\u001b[39mcall_args[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m--> 161\u001b[0m solver\u001b[38;5;241m.\u001b[39m_y, solver\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m=\u001b[39m integrator\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    162\u001b[0m     solver\u001b[38;5;241m.\u001b[39mf, solver\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m), solver\u001b[38;5;241m.\u001b[39m_y, solver\u001b[38;5;241m.\u001b[39mt,\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_bound, solver\u001b[38;5;241m.\u001b[39mf_params, solver\u001b[38;5;241m.\u001b[39mjac_params)\n\u001b[0;32m    164\u001b[0m integrator\u001b[38;5;241m.\u001b[39mcall_args[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m itask\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver\u001b[38;5;241m.\u001b[39msuccessful():\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\scipy\\integrate\\_ode.py:1347\u001b[0m, in \u001b[0;36mlsoda.run\u001b[1;34m(self, f, jac, y0, t0, t1, f_params, jac_params)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macquire_new_handle()\n\u001b[0;32m   1345\u001b[0m args \u001b[38;5;241m=\u001b[39m [f, y0, t0, t1] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_args[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m   1346\u001b[0m        [jac, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_args[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], f_params, \u001b[38;5;241m0\u001b[39m, jac_params]\n\u001b[1;32m-> 1347\u001b[0m y1, t, istate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mistate \u001b[38;5;241m=\u001b[39m istate\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m istate \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\scipy\\integrate\\_ivp\\base.py:154\u001b[0m, in \u001b[0;36mOdeSolver.__init__.<locals>.fun\u001b[1;34m(t, y)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun\u001b[39m(t, y):\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun_single(t, y)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\scipy\\integrate\\_ivp\\base.py:23\u001b[0m, in \u001b[0;36mcheck_arguments.<locals>.fun_wrapped\u001b[1;34m(t, y)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_wrapped\u001b[39m(t, y):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(fun(t, y), dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m, in \u001b[0;36mSolve_Concentration_SS.<locals>.dydt\u001b[1;34m(t, Y)\u001b[0m\n\u001b[0;32m     21\u001b[0m ratef \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(N_R) \u001b[38;5;28;01mif\u001b[39;00m law\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMM\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m kf\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     22\u001b[0m rater \u001b[38;5;241m=\u001b[39m kr\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 23\u001b[0m X_Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((X0, Y))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_R):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     prod \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mprod([s\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mp \u001b[38;5;28;01mfor\u001b[39;00m s,p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(X_Y, S_minus[:,l])])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main(num_networks=5, output_dir=r\"D:\\Simulation_Data\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    dm = DataManager(output_dir)\n",
    "    mgf_list, vn_alpha_list, vn_beta_list, entropy_list = [], [], [], []\n",
    "    run_idx = 0\n",
    "\n",
    "    while run_idx < num_networks:\n",
    "        Stot, N_X, N_Y, N_R, S_plus, S_minus = Generate_Random_Network(\n",
    "            N_X_raw=random.randint(3, 8),\n",
    "            N_Y_raw=random.randint(3, 8),\n",
    "            N_R_raw=random.randint(5, 15),\n",
    "            diluted=False, ambiguity=False, autonomy=True\n",
    "        )\n",
    "        S_plus_trim = S_plus[N_X:, :]\n",
    "        S_minus_trim = S_minus[N_X:, :]\n",
    "        _, _, auto = aux.checkAutonomy(S_minus_trim, S_plus_trim)\n",
    "        if not auto:\n",
    "            continue\n",
    "\n",
    "        ini_conc, kf, kr, kd, mu_X_actual, mu_0_vector, DeltaG0 = Construct_Kinetics(\n",
    "            N_X, N_Y, N_R, S_plus, S_minus, degradation=False\n",
    "        )\n",
    "        X0 = ini_conc[:N_X]\n",
    "        Y0 = ini_conc[N_X:]\n",
    "\n",
    "        try:\n",
    "            _, db_alpha, *_ = algo1.growthRateGraph(\n",
    "                S_plus_trim, S_minus_trim,\n",
    "                max_steps=1000, time_limit_iteration=100\n",
    "            )\n",
    "        except Exception:\n",
    "            continue\n",
    "        if np.isnan(db_alpha):\n",
    "            continue\n",
    "        mgf = db_alpha\n",
    "\n",
    "        vn_alpha, vn_beta = compute_von_neumann_alpha_beta(\n",
    "            S_plus_trim, S_minus_trim\n",
    "        )\n",
    "        if np.isnan(vn_alpha) or np.isnan(vn_beta):\n",
    "            continue\n",
    "\n",
    "        # Dynamic_Simulation\n",
    "        sol_t, sol_y, flux_ts, affinity_ts, energy_flow_ts, entropy_prod_ts, chemical_work_ts = \\\n",
    "            Dynamic_Simulation(\n",
    "                S_minus, S_plus, Stot,\n",
    "                X0, Y0, N_X, N_Y, N_R,\n",
    "                kf, kr, kd,\n",
    "                mu_X_actual,\n",
    "                law=\"MA\"\n",
    "            )\n",
    "\n",
    "        # Compute Shannon entropy\n",
    "        H = compute_shannon_entropy(sol_y[-1])\n",
    "\n",
    "        dm.save_run(\n",
    "            run_idx,\n",
    "            S_minus, S_plus,\n",
    "            sol_t, sol_y,\n",
    "            flux_ts, affinity_ts,\n",
    "            energy_flow_ts, entropy_prod_ts,\n",
    "            chemical_work_ts,\n",
    "            mgf, vn_alpha, vn_beta, H\n",
    "        )\n",
    "        mgf_list.append(mgf)\n",
    "        vn_alpha_list.append(vn_alpha)\n",
    "        vn_beta_list.append(vn_beta)\n",
    "        entropy_list.append(H)\n",
    "        run_idx += 1\n",
    "\n",
    "    dm.finalize()\n",
    "\n",
    "    # Plot\n",
    "    def scatter_and_save(x, y, xlabel, ylabel, filename):\n",
    "        plt.figure()\n",
    "        plt.scatter(x, y)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, filename))\n",
    "        plt.close()\n",
    "\n",
    "    arrs = {\n",
    "        'vn_alpha': np.array(vn_alpha_list),\n",
    "        'vn_beta':  np.array(vn_beta_list),\n",
    "        'mgf':      np.array(mgf_list),\n",
    "        'entropy':  np.array(entropy_list)\n",
    "    }\n",
    "    scatter_and_save(arrs['vn_alpha'], arrs['mgf'], \"von Neumann α\", \"MGF\", \"vn_alpha_vs_mgf.png\")\n",
    "    scatter_and_save(arrs['vn_alpha'], arrs['vn_beta'], \"von Neumann α\", \"von Neumann β\", \"vn_alpha_vs_vn_beta.png\")\n",
    "    scatter_and_save(arrs['vn_beta'], arrs['entropy'], \"von Neumann β\", \"Shannon Entropy\", \"vn_beta_vs_entropy.png\")\n",
    "    scatter_and_save(arrs['vn_alpha'], arrs['entropy'], \"von Neumann α\", \"Shannon Entropy\", \"vn_alpha_vs_entropy.png\")\n",
    "    scatter_and_save(arrs['mgf'], arrs['entropy'], \"MGF\", \"Shannon Entropy\", \"mgf_vs_entropy.png\")\n",
    "\n",
    "    print(f\"Finished simulation of {num_networks} networks. Results in {output_dir}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
